[{"title":"linux 离线安装 oracle JDK","url":"/JDK/","content":"摘要:\n  本文是在deepin linux(基于debian发行版)系统环境下,debian,ubuntu以及其他debian衍生版同理适用\n\n如果电脑处于联网状态，那么可以使用 apt 包管理器在线安装，可使用以下命令在线安装:\nsudo apt update #更新\nsudo apt install oracle-java8 #安装\n 下面重点介绍离线安装官网下载安装包的方式:\n 1.oracle 官网下载 Linux 对应的 tar.gz 安装包\n 2. 进入到存放安装包的目录下，执行以下命令将安装包的内容解压到在指定目录 (/usr/local/java/ 文件夹自己事先建好)\n sudo tar zxvf ./xxxx.tar.gz  -C /usr/local/java\n3. 查看第二步是否成功，如果有 /usr/local/java/ 下有 jdk 对应的目录结构，则表示成功\nls -anl /usr/local/java/\n4. 配置环境变量 (此处配置到当前用户的环境变量上)\nsudo  vim ~/.bashrc #用vim打开当前用户的环境变量配置文件\n在.bashrc 文件底部加入以下内容，然后保存退出\nexport JAVA_HOME=/usr/local/java/java-8u5_xxx\n\nexport JRE_HOME=${JAVA_HOME}/jre   \n\nexport CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib   \n\nexport PATH=${JAVA_HOME}/bin:$PATH\n\nunset _JAVA_OPTIONS\n\n5. 执行以下命令使刚刚的配置生效\nsource ~/.bashrc\n6. 验证安装结果，执行下列命令，如果一切无误，会正常出现对应的 java 版本信息\njava -version\n","tags":["linux","java","jdk"]},{"title":"Linux 常用压缩解压缩","url":"/Linux%E5%B8%B8%E7%94%A8%E5%8E%8B%E7%BC%A9%E8%A7%A3%E5%8E%8B%E7%BC%A9/","content":"摘要:\n  Linux下常用的压缩格式有:.zip .gz .bz2 .tar.gz .tar.bz2\n\n1 .zip 格式压缩压缩文件 zip 压缩文件名 源文件\nzip test.zip ./test.txt #将当前目录的test.txt文档压缩为test.zip\n\n压缩目录 zip -r 压缩文件名 源目录\nzip test1.zip ./test1 #将当前目录的test1目录压缩为test1.zip\n\n2 .zip 格式解压缩解压文件  unzip 压缩文件\nzip ./test1.zip #解压缩当前目录的test1.zip文件\n\n3 .gz 格式压缩压缩为.gz 文件，源文件消失  gzip 源文件\n压缩为.gz 文件，源文件保留  gzip -c 源文件 &gt; 压缩文件\n压缩目录下的所有子文件，但是不能压缩目录  gzip -r 目录\n4 .gz 格式解压缩解压缩.gz 文件  gzip -d 压缩文件\n解压缩.gz 文件  gunzip  压缩文件\n5 .bz2 格式压缩压缩为.bz2 格式，不保留源文件  bzip2 源文件\n压缩为.bz2 格式，保留源文件 bzip2 -k 源文件\n注:bzip2 不能压缩目录\n6 .bz2 格式解压缩解压缩.bz2 文件，-k 保留压缩文件  bzip2 -d 压缩文件\n解压缩.bz2 文件，-k 保留压缩文件  bunzip2 压缩文件\n7 .tar.gz 格式压缩 (先打包为 tar, 再压缩为.gz 文件)tar 打包命令  tar -cvf 打包文件名 源文件\n选项: -c 打包；-v 现实过程；-f 指定打包后的文件名\ntar -cvf test.tar ./test 将当前目录下 test 目录打包为 tar 文件\ngzip test.tar  生成 test.tar.gz 文件\nbzip2 test.tar 生成 test.tar.bz2 文件\n上述过程繁琐，可以直接用  tar -zcvf 压缩包名.tar.gz 源文件\n8 .tar.gz 格式解压缩 (先用 gzip 解压文件，然后解打包)解打包命令  tar -xvf 打包文件名\n选项: -x 解打包\ntar -vxf test.tar   解包 text.tar 文件\n上述过程繁琐，可以直接用  tar -zxvf 压缩包名.tar.gz,解压到指定目录可用 - C 选项指定目录 tar -zxvf 压缩包名.tar.gz -C /tmp/\n9 .tar.bz2 格式压缩 (先打包为 tar, 再压缩为.bz2 文件)tar 打包命令  tar -cvf 打包文件名 源文件\n选项: -c 打包；-v 现实过程；-f 指定打包后的文件名\ntar -cvf test.tar ./test 将当前目录下 test 目录打包为 tar 文件\nbzip2 test.tar 生成 test.tar.bz2 文件\n上述过程繁琐，可以直接用  tar -jcvf 压缩包名.tar.bz2 源文件\n10 .tar.bz2 格式解压缩 (先用 bzip2 解压文件，然后解打包)解打包命令  tar -xvf 打包文件名\n选项: -x 解打包\ntar -vxf test.tar   解包 text.tar 文件\n上述过程繁琐，可以直接用  tar -jxvf 压缩包名.tar.bz2,解压到指定目录可用 - C 选项指定目录 tar -jxvf 压缩包名.tar.bz2 -C /tmp/\n","tags":["linux"]},{"title":"Linux 增加使用文件代替 swap 分区分方法","url":"/Linux%E5%A2%9E%E5%8A%A0%E4%BD%BF%E7%94%A8%E6%96%87%E4%BB%B6%E4%BB%A3%E6%9B%BFswap%E5%88%86%E5%8C%BA%E5%88%86%E6%96%B9%E6%B3%95/","content":"摘要:\n  在安装Linux系统的时候未对系统进行swap(交换分区),后续进入系统\n  可以采用新建文件的方式来代替swap分区.\n  以下所执行的系统环境是:deepin linux(基于debian发行版),\n  按理在Ubuntu,debian上也是可以的.\n\n注意：执行以下命令时，全部采用 root 账户的权限\n1. 创建要作为 swap 分区的文件：增加 1GB 大小的交换分区，则命令写法如下，其中的 count 等于想要的块的数量（bs*count = 文件大小）\nsudo dd if=/dev/zero of=/swapfile bs=1M count=1024\n2. 格式化为交换分区文件，建立 swap 的文件系统\nsudo mkswap /swapfile\n3. 启用交换分区文件\nsudo swapon /swapfile\n4. 使系统开机时自启用，在文件 /etc/fstab 中添加一行 (可使用 vim 打开文件进行编辑)：\n/swapfile swap swap defaults 0 0\n5. 验证结果，执行 free 命令查看是否有交换分区\nfree -m \n注：如果想移除 swap 分区文件，执行以下命令:\nsudo swapoff /swapfile &amp;&amp; sudo rm /swapfile\n","tags":["linux","swap"]},{"title":"Linux 下安装 maven","url":"/Linux%E4%B8%8B%E5%AE%89%E8%A3%85maven/","content":"摘要:\n  Linux系统下离线安装maven\n\n1. 在 Apache 官方网站下载对应系统的 maven 包然后解压 maven\n2. 配置环境变量.(配置到当前用户的环境变量上)\nsudo  vim ~/.bashrc #用vim打开当前用户的环境变量配置文件\n在.bashrc 文件底部加入以下内容，然后保存退出.(M2_HOME 代表解压后的 maven 目录)\nexport M2_HOME=/home/user/apache-maven-3.3.9\n\nexport PATH=${M2_HOME}/bin:$PATH\n\n3. 执行以下命令使刚刚的配置生效\n`source ~/.bashrc`\n\n4. 验证安装结果，执行下列命令，如果一切无误，会正常出现对应的 maven 版本信息\n`mvn -v`\n\n","tags":["linux","java","maven"]},{"title":"Linux 下离线安装 nodejs","url":"/Linux%E4%B8%8B%E5%AE%89%E8%A3%85nodejs/","content":"Linux 下离线安装 nodejs 步骤:\n1. 在官网下载 Linux 版本的 nodejs 安装包，然后解压并且移动到 /usr/local/ 目录，具体目录可随意指定\nsudo tar -xvJf ./node-v8.9.3-linux-x64.tar.xz -C /usr/local/\n2. 配置环境变量，编辑～/.bashrc 文件 (当前用户的环境变量配置)\nexport NODE_HOME=/opt/node\nexport PATH=$PATH:$NODE_HOME/bin\nexport NODE_PATH=$NODE_HOME/lib/node_modules\n3. 使配置生效，执行 source 命令\nsource ~/.bashrc\n4. 执行如下命令校验配置是否生效\nnode -v\nnpm -v\n","tags":["linux","nodejs"]},{"title":"MySQL 字段值默认不区分大小写问题","url":"/MySQL%E5%AD%97%E6%AE%B5%E5%80%BC%E9%BB%98%E8%AE%A4%E4%B8%8D%E5%8C%BA%E5%88%86%E5%A4%A7%E5%B0%8F%E5%86%99%E9%97%AE%E9%A2%98/","content":"摘要：\n  mysql的字段值是默认不区分大小写的,但是用户在登录账户的时候严格区分大小写的,所以解决如下:\n\n1 . 在不改变表任何结构的情况下，可以直接在查询条件后面的字段名或者字段值作为 binary () 函数的参数即可，如下:\nselect * from table_name t where binary(t.field) = 'Abc';\n2 . 在建表的时候在字段后面加上 binary, 或者用 alter 语句来改变字段类型，只需要加上 binary\n`mysql&gt; create table t_user(\n\n-&gt; username varchar(20) binary\n\n-&gt; );`\n\n对已有的表进行 alert\nalter table table_name modify field varchar(20) binary\n注:table_name 换成具体对应的表名称.field 换成具体对应的表的字段\n","tags":["MySQL"]},{"title":"MySQL 中 utf8 和 utf8mb4 区别对 emoji 支持","url":"/MySQL%E4%B8%ADutf8%E5%92%8Cutf8mb4%E5%8C%BA%E5%88%AB%E5%AF%B9emoji%E6%94%AF%E6%8C%81/","content":"摘要:\n  MySQL在5.5.3之后增加了这个utf8mb4的编码，mb4就是most bytes 4的意思，专门用来兼容\n  四字节的unicode。好在utf8mb4是utf8的超集，除了将编码改为utf8mb4外不需要做其他转换。\n  当然，为了节省空间，一般情况下使用utf8也就够了.\n  查看当前的MySQL版本:\n  mysql&gt; select version();\n  或者\n  mysql --version\n\nutf8 不支持 emoji 表情的问题  当使用 utf8 字符集的时候，插入 emoji 表情符号会提示” Incorrect string value: ‘\\xXX\\xXX\\xXX\\xXX’ for column……”, 原因在于 MySQL 中 utf8 字符集只支持三字节 UTF-8 编码的 Unicode 范围，而 emoji 字符属于四字节编码部分。此时，需要将库表的字符集更改为 utf8mb4\n修改字符集为 utf8mb4  修改 /etc/mysql/my.cnf 文件或者 /etc/mysql/mysql.conf.d/mysqld.cnf 文件，修改以下参数:\n[client]\ndefault-character-set=utf8mb4\n  \n  \n[mysql]\ndefault-character-set=utf8mb4\n  \n  \n[mysqld]\ncharacter-set-server = utf8mb4\ncollation-server = utf8mb4_unicode_ci\ninit_connect = 'SET NAMES utf8mb4'\ncharacter-set-client-handshake = false\n\n注:\n1.init_connect='SET NAMES utf8mb4' 表示初始化连接都设置为utf8mb4字符集;\n2.skip-character-set-client-handshake = true 忽略客户端字符集设置，不论客户端是何种字符集，都按照init_connect中的设置进行使用\n\n对数据库相关的表进行字符集修改建立新库和表的情况，直接使用 utf8mb4 字符CREATE DATABASE IF NOT EXISTS test default charset utf8mb4 COLLATE utf8mb4_unicode_ci;\n\nCREATE TABLE `t_table`  (\n  `id` varchar(36) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NOT NULL,\n  `create_time` datetime(0) NULL DEFAULT NULL,\n  'comment' varchar(100) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NOT NULL,\n  PRIMARY KEY (`id`) USING BTREE\n) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_unicode_ci ROW_FORMAT = Dynamic;\n\n已经存在表的情况，对库，表和字段都修改为 utf8mb4mysql&gt; ALTER DATABASE test CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;\n\nmysql&gt;ALTER TABLE `t_table` CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;\n\nmysql&gt;ALTER TABLE `t_table` MODIFY COLUMN `comment`  varchar(100) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;\n\n重启 MySQL 服务/etc/init.d/mysqld restart 或者service mysql restart\n\n登录数据库查看字符集是否更改成功mysql&gt; SHOW VARIABLES WHERE Variable_name LIKE 'character%' OR Variable_name LIKE 'collation%';\n\n+--------------------------+----------------------------+\n| Variable_name            | Value                      |\n+--------------------------+----------------------------+\n| character_set_client     | utf8mb4                    |\n| character_set_connection | utf8mb4                    |\n| character_set_database   | utf8mb4                    |\n| character_set_filesystem | binary                     |\n| character_set_results    | utf8mb4                    |\n| character_set_server     | utf8mb4                    |\n| character_set_system     | utf8                       |\n| character_sets_dir       | /usr/share/mysql/charsets/ |\n| collation_connection     | utf8mb4_unicode_ci         |\n| collation_database       | utf8mb4_unicode_ci         |\n| collation_server         | utf8mb4_unicode_ci         |\n+--------------------------+----------------------------+\n\n\n关于Windows下MySQL的一点坑:\n之前一个旧式的服务器采用的是Windows server2012,mysql使用的是安装版的.安装路径在\nC:\\Program Files\\MySQL\\MySQL Server 5.6下.有个my-default.ini配置文件,\n但是无论对这个文件如何配置修改,重启服务器都无效.经过多方搜索,发现Windows下MySQL服务\n默认使用的不是该文件,而是采用C:\\ProgramData\\MySQL\\MySQL Server 5.6下的my.ini\n这个文件.所以需要对这个文件修改才能使其生效.\n\n","tags":["MySQL"]},{"title":"MySQL 新版本设置 root 密码和重置 root 密码","url":"/MySQL%E6%96%B0%E7%89%88%E6%9C%AC%E8%AE%BE%E7%BD%AEroot%E5%AF%86%E7%A0%81%E5%92%8C%E9%87%8D%E7%BD%AEroot%E5%AF%86%E7%A0%81/","content":"&gt; 摘要:最近在虚拟机上安装Ubuntu18.04版本,然后安装MySQL-server.安装MySQL-server过程中不再像之前会提示\n输入root账户的密码.所以需要进行对root账户设置密码,\n\n&gt;操作环境:\n    OS:Ubuntu 18.04\n    MySQL版本:5.7及更高\n\n1. 前置条件需要系统的root账户或者使用sudo 命令\n\n2. 使用 mysql_secure_installation 进行对密码设置如果是第一次安装完MySQL后,可以使用:\n\nsudo mysql_secure_installation  对root账户进行设置密码操作\n\n3. 使用 skip-grant-tables 对 root 账户进行重置密码的操作3.1 停止当前正在运行的mysql服务\n\n    sudo service mysql stop\n\n3.2 创建/var/run/mysqld目录,因为MySQL进程在启动和运行的时候都需要访问该soket文件\n\n    sudo mkdir -p /var/run/mysqld\n    sudo chown mysql:mysql /var/run/mysqld\n\n3.3 使用skip-grant-tables启动服务程序\n\n    sudo /usr/sbin/mysqld --skip-grant-tables --skip-networking &amp;\n\n    jobs 然后确认下服务是否启动成功\n\n3.4 使用root无密码登录,进行修改设置密码操作\n\n    mysql -u root root无密码登录\n\n    FLUSH PRIVILEGES; 刷新一遍授权信息\n\n    USE mysql; 切换到mysql库(安装好后自带的)\n\n    UPDATE user SET authentication_string=PASSWORD(\"123456\") WHERE User='root'; 设置密码字段的新密码,\n    authentication_string是新版本存储密码的字段名,旧版本的是password.\n\n    UPDATE user SET plugin=\"mysql_native_password\" WHERE User='root';\n\n    FLUSH PRIVILEGES;\n\n    quit;\n\n3.5 重启MySQL服务\n\n    sudo pkill mysqld  停掉之前启动的服务\n\n    jobs 查看是否正确停止服务\n\n    sudo service mysql start 启动MySQL服务\n\n3.6 使用root账户和刚设置的密码进行登录操作\n\n    mysql -u root --password=123456  使用root和密码登录\n\n    \n\n","tags":["MySQL"]},{"title":"Shell 基础","url":"/Shell%E5%9F%BA%E7%A1%80/","content":"摘要:\n  Shell是一个命令行解释器,它为用户提供了一个向Linux内核\n  发送请求以便运行程序的界面系统级程序.用户可以用Shell来启动,挂起,\n  停止甚至是编写一些程序.\n  Shell还是一个功能相当强大的编程语言.易编写,意调试,灵活性较强.\n  Shell是解释执行的语言,在Shell中可以直接调用Linux系统命令.\n\n1. 脚本的执行方式1. echo 输出命令\n    echo [选项] [输出内容]\n    选项:\n      -e : 支持反斜杠控制的字符转换\n\n2. 编写第一个脚本\n  vim hello.sh\n  #!/bin/bash\n  # this is hello program!\n  echo \"hello\"\n\n3. 脚本执行\n  1.赋予执行权限  \n    chmod 755 ./hello.sh\n    ./hello.sh\n  2.通过bash调用执行脚本\n    bash ./hello.sh\n  3.使用sh命令执行\n    sh ./hello.sh\n\n2.Bash 的基本功能1. 命令的别名,很多泛指为Linux下的命令,其实本质是属于Bash\n  `alias` 查看系统中所有的命令的别名\n2. 设置命令别名\n  alias 别名= '原命令'\n  alias ll='ls -l'  #给ls -l 设置别名ll\n\n  以上设置别名的方式只是当次有效,系统重启后无效.要设置别名永久有效,\n  可以写入环境变量中\n  vim ~/.bashrc\n  alias ll='ls -l'\n  保存,执行source ~/.bashrc即可\n\n3. 删除别名\n  unalias 别名\n  unalias ll\n  unalias是删除临时别名的,永久生效的别名需要删除环境变量中的配置\n\n4. 命令的生效顺序\n  第一顺位执行用绝对路径或者相对路径的命令\n  第二顺位执行别名\n  第三顺位执行Bash的内部命令\n  第四顺位执行按照$PATH环境变量定义的目录查找顺序找到的第一个命令\n\n  注:因为别名的执行顺序是高于$PATH下的命令的,\n  所以一般情况下请勿将别名设为与其他原始命令相同的命令.\n\n3.Shell 编程之 Bash 变量  Shell 中，所有变量默认都是字符串类型\n\n用户自定义变量  变量名 = 变量值 (等号 2 边不能有空格) \n\n用户自己定义的变量,变量名和值可随意更改\n\nname=\"zhangsan\"\n\necho $name #显示name的值\n\n1.1 变量叠加\n\n  name=\"$name\"isaname\n\n1.2  删除变量(释放变量的内存地址) unset 变量名\n\n\n环境变量\n\n环境变量是全局变量,用户可更改值,不能更改名称\n\n\n位置参数变量 \n\n$n :n为数字,$0代表命令本身.$1-$9代表第1-第9个参数,10以上的参数需要用大括号包含,如${10}\n\n例:vim sum.sh\n\n  `#!/bin/bash\n\n    num1=$1\n\n    num2=$2\n\n    sum=$(($num1+$num2))\n\n    #变量sum的和是num1+num2\n\n    echo $sum`\n\n    执行;./sum.sh 10 20  #./sum.sh是$0,10是$1,20是$2\n\n    结果:30\n\n$* : 这个变量代表命令行中中所有的参数,$* 把所有的参数看成一个整体\n\n$@ : 这个变量也代表命令行中所有的参数,不过$@ 是把每个参数区分对待\n\n@# : 这个变量代表命令行中所有参数的个数\n\n例:vim /demo.sh\n\n`#!/bin/bash\n\necho \"参数是: $* \"\n\necho \"参数也是: $@ \"\n\necho \"参数个数是: $#\"`\n\n执行;./demo.sh 11 22 33\n\n结果:参数是: 11 22 33 参数也是: 11 22 33 参数个数是: 3\n\n$* 和 $@ 区别\n\nvim ./demo.sh\n\n#!/bin/bash\n\n`for i in \"$*\"\n\n#$* 把所有的参数看成一个整体,所以执行循环1次\n\n  do\n\n    echo \"参数是: $i\"\n\n  done\n\nfor y in \"$@\"\n\n#$@ 是把每个参数区分对待,所有有几个参数就循环几次\n\n  do\n\n    echo \"参数是: $y\"\n\n  done\n`\n\n\n预定义变量 \n\n$? : 最后依次执行的命令的返回结果,如果返回是0,代表上一个命令执行成功,如果返回是非0,代表上一个命令执行失败\n\n$$ : 返回当前进程的PID号\n\n$! : 后台运行的最后一个进程的进程号(PID)\n\n\n接收键盘输入:read 命令 \n\nread [选项] [变量名]\n\n选项\n\n  -p \"提示信息\":在等待read输入时,输出提示信息\n\n  -t 秒数: read命令会一直等待用户输入,输入次选项可以指定用户等待时间\n\n  -n 字符数: read命令只接受指定的字符数,就会执行\n\n  -s : 隐藏输入的数据,适用于输入密码等情况\n\n4.Shell 编程之运算符1. declare命令\n\n  declare声明变量类型\n\n  declare [+/-] [选项] 变量名\n\n    选项:用-给变量设定类型属性,用+取消变量的类型属性\n\n  常见选项类型\n\n    -a 将变量声明为数组类型\n\n    -i 将变量声明为整形\n\n    -x 将变量声明为环境变量\n\n    -r 将变量声明为只读变量(设置为只读属性后,不能对变量进行删除,修改,取消属性的操作)\n\n    -p 查看显示指定变量的被声明的类型\n\n2. 数值运算的方法\n\n  方法1:\n\n  [root@localhost~]# aa=11\n\n  [root@localhost~]# bb=22\n\n  [root@localhost~]# declare -i cc=$aa+$bb\n\n  方法2:\n\n    expr或者let数值运算工具\n\n    [root@localhost~]# aa=11\n\n    [root@localhost~]# bb=22\n\n    [root@localhost~]# dd=$(expr $aa + $bb)\n\n    #dd的值是aa和bb的和,注意:\"+\"号两侧必须有空格\n\n  方法3:\n\n    \"$(())\"或\"$[运算式]\"\n\n    [root@localhost~]# aa=11\n\n    [root@localhost~]# bb=22\n\n    [root@localhost~]# cc=$(($aa + $bb))\n\n    [root@localhost~]# gg=$[$aa + $bb]\n\n3. 变量测试(只是针对Shell,其他常用不适用.一般不常用,对脚本进行优化的时候才使用)\n\n5.Shell 编程之环境变量配置文件`/etc/profile\n\n/etc/profile.d/*.sh\n\n/etc/bashrc\n\n~/.bashrc\n\n~/.bash_profile`\n\n/etc目录下的是系统环境变量文件,~目录下的是当前用户的环境变量配置文件\n\n6.Shell 编程之正则表达式正则表达式主要是用于描述字符排列和匹配模式d额一种语法规则，\n主要用于字符串的模式分割,匹配,查找及替换操作\n\n  1. 正则表达式与通配符\n通配符：\n  *：匹配任意内容\n  ?：匹配任意一个内容\n  []：匹配括号中的一个字符.\n\n  正则表达式用来在文件中匹配符合条件的字符串，正则是包含匹配.  grep,awk,sed 等命令可以支持正则表达式.\n  通配符用来匹配符合条件的文件名，通配符是完全匹配.  ls,find,cp 这些命令不支持正则表达式，所以只能使用 shell 的通配符匹配.\n基础正则表达式:  | 元字符 | 作用 |  | - | :-: | -: |  |*| 前一个字符匹配 0 次或者任意多次 |  |.| 匹配除了换行符以外的任意一个字符 |  |^| 匹配行首。例如:^hello 匹配以 hello 开头的行 |  |$| 匹配行尾。例如:hello$ 匹配以 hello 结尾的行 |  |[]| 匹配中括号中指定的任意一个字符，只匹配一个字符 |  |[^]| 匹配除中括号中的字符以外的任意一个字符，例:[^0-9] 表示匹配任意一位非数字字符 |  |\\| 转义符，用于将特殊符号的含义取消 |  |\\{n\\}| 表示其前面的字符恰好出现 n 次。例:[0-9]\\{4\\} 匹配 4 位数字 |  |\\{n,\\}| 表示其前面出现的字符不小于 n 次，例:[0-9]\\{2,\\} 表示 2 位及以上的数字 |  |\\{n,m\\}| 表示其前面出现的字符至少出现 n 次，最多出现 m 次，例:[a-z]\\{2,4\\} 匹配 2 到 4 位的小写字母 |\n","tags":["linux","shell"]},{"title":"MySQL 设置用户远程登录","url":"/MySQL%E8%AE%BE%E7%BD%AE%E7%94%A8%E6%88%B7%E8%BF%9C%E7%A8%8B%E7%99%BB%E5%BD%95/","content":"摘要:在Linux(debian)下,通过apt install mysql-server后,输入root账户密码后,\n默认是不允许远程登录的.可以用过以下几种方式来设置允许能够远程登录\n\n1. 改 mysql 库下的 user 表的数据\nmysql -u root –p\nmysql&gt;use mysql;\nmysql&gt;update user set host = '%' where user = 'root';\nmysql&gt;select host, user from user;\n\n2. 通过授权的方式，这种方式可以对不同的用户设置不同的访问权限\n#例如: 在MySQL服务器主机上执行,允许root使用123456从任何主机连接到mysql服务器\n\nmysql&gt;GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY '123456' WITH GRANT OPTION;\n\nmysql&gt;FLUSH PRIVILEGES; # 刷新权限,使配置生效\n\n#例如:允许用户test从ip为120.77.163.89的主机连接到mysql服务器，并使用123456作为密码\n\nmysql&gt;GRANT ALL PRIVILEGES ON *.* TO 'test'@’120.77.163.89’ IDENTIFIED BY '654321' WITH GRANT OPTION;\n\nmysql&gt;FLUSH PRIVILEGES; # 刷新权限,使配置生效\n\n","tags":["MySQL"]},{"title":"axis2 调用 webservice","url":"/axis2%E8%B0%83%E7%94%A8webservice/","content":"\n\n\nWebService: 一种跨编程语言和跨操作系统平台的远程调用技术.\nWebService 的实现包有很多，Java 语言有 jdk1.6 后内置的 jws.*,Apache cxf,Apache Axis,Apache Axis2.\n1. 远程调用\n1.1 axis2+wsdl 地址方式调用:\n1.2 axis2+endpoint 地址方式调用:\n\n\n2.wsdl2java 方式调用\n\n\n\n\nWebService: 一种跨编程语言和跨操作系统平台的远程调用技术.WebService都是基于http请求(POST请求,无GET请求)\nXML+XSD,SOAP和WSDL就是构成WebService平台的三大技术。\nXML+XSD：\n\nWebService采用HTTP协议传输数据，采用XML格式封装数据（即XML中说明调用远程服务对象的哪个方法，传递的参数是什么，\n以及服务对象的返回结果是什么）。XML是WebService平台中表示数据的格式。\n\nSOAP(Simple Object Access Protocol)：简单对象访问协议\n\nSOAP提供了标准的RPC方法来调用Web Service。SOAP协议 = HTTP协议 + XML数据格式SOAP协议定义了SOAP消息的格式，\nSOAP协议是基于HTTP协议的，SOAP也是基于XML和XSD的，XML是SOAP的数据编码方式。\nsoap协议分1.1和1.2版本:\nsoap1.1:\n  请求方式:post\n  content-type:text/xml;charset=utf-8\nsoap1.2:\n  请求方式:post\n  content-type:application/soap+xml\n\nWSDL(Web Services Description Language):基于XML的语言，用于描述Web Service及其函数、参数和返回值。\n\n它是WebService客户端和服务器端都能理解的标准格式。WSDL文件保存在Web服务器上，通过一个url地址就可以访问到它。\n客户端要调用一个WebService服务之前，要知道该服务的WSDL文件的地址。\n\n注:wsdl文件阅读技巧:(从下往上读)\n  找到wsdl:service节点-&gt;查看下面的wsdl:port节点-&gt;查看其binding属性-&gt;找到与bingding名称相同的wsdl:binding节点\n  -&gt;查看节点下的wsdl:operation节点(对应的调用method名称)-&gt;wsdl:input方法输入参数节点-&gt;对应message属性值\n  -&gt;找到同名的wsdl:message节点-&gt;wsdl:part对应的参数名称和类型.\n\n  wsdl:output节点代表服务返回的数据.阅读方式和wsdl:input一致\n\nWebService 优点：跨平台跨语言。服务方和调用方不用关心各自的平台和语言\nWebService 缺点：在使用方式上，RPC 和 soap 的使用在减少，Restful 架构占到了主导地位。在数据格式上，XML 格式繁琐，使用在减少，json 等轻量级格式的使用在增多.. 另外性能上略低 (也有专门对 xml 解析优化的 cpu)\nWebService 的实现包有很多，Java 语言有 jdk1.6 后内置的 jws.*,Apache cxf,Apache Axis,Apache Axis2.本文采用 axis2 包，发布 webservice 服务可以采用 jdk 的 @WebService 注解实现或者 cxf/axis/axis2 来进行实现，网上教程很多，本文不涉及到这块。主要是发现在调用的时候会有一些坑，所以在此记录\nWebService 客户端调用主要有 2 类方式，一种是通过 http 远程调用，一种是通过 wsdl2java 产生 Java 代码调用\n1. 远程调用  引入 axisjar 包:  &lt;!-- Axis2 --&gt;\n  &lt;dependency&gt;\n      &lt;groupId&gt;org.apache.axis2&lt;/groupId&gt;\n      &lt;artifactId&gt;axis2&lt;/artifactId&gt;\n      &lt;version&gt;1.6.2&lt;/version&gt;\n  &lt;/dependency&gt;\n  &lt;dependency&gt;\n      &lt;groupId&gt;org.apache.ws.commons.axiom&lt;/groupId&gt;\n      &lt;artifactId&gt;axiom&lt;/artifactId&gt;\n      &lt;version&gt;1.2.20&lt;/version&gt;\n      &lt;type&gt;pom&lt;/type&gt;\n  &lt;/dependency&gt;\n  &lt;dependency&gt;\n      &lt;groupId&gt;org.apache.ws.commons.axiom&lt;/groupId&gt;\n      &lt;artifactId&gt;axiom-api&lt;/artifactId&gt;\n      &lt;version&gt;1.2.20&lt;/version&gt;\n  &lt;/dependency&gt;\n  &lt;dependency&gt;\n      &lt;groupId&gt;org.apache.ws.commons.axiom&lt;/groupId&gt;\n      &lt;artifactId&gt;axiom-impl&lt;/artifactId&gt;\n      &lt;version&gt;1.2.20&lt;/version&gt;\n  &lt;/dependency&gt;\n  &lt;dependency&gt;\n      &lt;groupId&gt;wsdl4j&lt;/groupId&gt;\n      &lt;artifactId&gt;wsdl4j&lt;/artifactId&gt;\n      &lt;version&gt;1.6.3&lt;/version&gt;\n  &lt;/dependency&gt;\n  &lt;dependency&gt;\n      &lt;groupId&gt;org.apache.ws.xmlschema&lt;/groupId&gt;\n      &lt;artifactId&gt;xmlschema-core&lt;/artifactId&gt;\n      &lt;version&gt;2.2.3&lt;/version&gt;\n  &lt;/dependency&gt;\n  &lt;dependency&gt;\n      &lt;groupId&gt;org.apache.neethi&lt;/groupId&gt;\n      &lt;artifactId&gt;neethi&lt;/artifactId&gt;\n      &lt;!--&lt;version&gt;2.0.4&lt;/version&gt; --&gt;\n      &lt;version&gt;3.1.1&lt;/version&gt;\n  &lt;/dependency&gt;\n  &lt;dependency&gt;\n      &lt;groupId&gt;org.apache.axis2&lt;/groupId&gt;\n      &lt;artifactId&gt;axis2-transport-local&lt;/artifactId&gt;\n      &lt;version&gt;1.7.7&lt;/version&gt;\n  &lt;/dependency&gt;\n  &lt;dependency&gt;\n      &lt;groupId&gt;org.apache.axis2&lt;/groupId&gt;\n      &lt;artifactId&gt;axis2-transport-http&lt;/artifactId&gt;\n      &lt;version&gt;1.7.7&lt;/version&gt;\n  &lt;/dependency&gt;\n  &lt;dependency&gt;\n      &lt;groupId&gt;javax.mail&lt;/groupId&gt;\n      &lt;artifactId&gt;javax.mail-api&lt;/artifactId&gt;\n      &lt;version&gt;1.6.2&lt;/version&gt;\n  &lt;/dependency&gt;\n&lt;!-- Axis2 End --&gt;\n1.1 axis2+wsdl 地址方式调用:String soapBindingAddress = \"http://ws.webxml.com.cn/WebServices/MobileCodeWS.asmx?wsdl\";\n      EndpointReference endpointReference = new EndpointReference(soapBindingAddress);\n      //创建一个OMFactory\n      OMFactory factory = OMAbstractFactory.getOMFactory();\n      //指定命名空间\n      OMNamespace namespace = factory.createOMNamespace(\"http://WebXml.com.cn/\", \"web\");\n      //创建method对象，方法名 为getMobileCodeInfo\n      OMElement method = factory.createOMElement(\"getMobileCodeInfo\", namespace);\n      OMElement mobileCode = factory.createOMElement(\"mobileCode\", namespace);//方法参数\n      OMElement userID = factory.createOMElement(\"userID\", namespace);//方法参数\n      //封装参数\n      mobileCode.addChild(factory.createOMText(mobileCode, \"18265963256\"));//设定参数的值\n      method.addChild(mobileCode);\n      userID.addChild(factory.createOMText(userID, \"\"));//设定参数的值\n      method.addChild(userID);\n      //请求参数设置\n      ServiceClient sender = new ServiceClient();\n      Options options = new Options();\n      // 设置soap1.2协议\n      options.setSoapVersionURI(SOAP12Constants.SOAP_ENVELOPE_NAMESPACE_URI);\n      options.setAction(\"http://WebXml.com.cn/getMobileCodeInfo\");\n      options.setTo(endpointReference);\n      sender.setOptions(options);\n      OMElement result = sender.sendReceive(method);\n      System.out.println(result.getFirstElement().getText());\n\n1.2 axis2+endpoint 地址方式调用:ServiceClient client = new ServiceClient();\n      // 创建服务地址WebService的URL,注意不是WSDL的URL\n      String url = \"http://ws.webxml.com.cn/WebServices/MobileCodeWS.asmx\";\n      EndpointReference targetEPR = new EndpointReference(url);\n      Options options = client.getOptions();\n      // 设置soap1.2协议\n      options.setSoapVersionURI(SOAP12Constants.SOAP_ENVELOPE_NAMESPACE_URI);\n      options.setTo(targetEPR);\n      // 确定调用方法（wsdl 命名空间地址 (wsdl文档中的targetNamespace) 和 方法名称 的组合）\n      options.setAction(\"http://WebXml.com.cn/getMobileCodeInfo\");\n      OMFactory fac = OMAbstractFactory.getOMFactory();\n      /*\n       * 指定命名空间，参数： uri--即为wsdl文档的targetNamespace，命名空间 perfix--可不填\n       */\n      OMNamespace omNs = fac.createOMNamespace(\"http://WebXml.com.cn/\", \"\");\n      /*\n       * 身份验证\n       * OMElement header = fac.createOMElement(\"AuthenticationToken\", omNs);\n       * OMElement ome_user = fac.createOMElement(\"Username\", omNs); OMElement\n       * ome_pass = fac.createOMElement(\"Password\", omNs);\n       *\n       * ome_user.setText(\"user\"); ome_pass.setText(\"pass\");\n       *\n       * header.addChild(ome_user); header.addChild(ome_pass);\n       *\n       * client.addHeader(header);\n       */\n      // 指定方法\n      OMElement method = fac.createOMElement(\"getMobileCodeInfo\", omNs);\n      // 指定方法的参数\n      OMElement mobileCode = fac.createOMElement(\"mobileCode\", omNs);\n      mobileCode.setText(\"18265963256\");\n      OMElement userID = fac.createOMElement(\"userID\", omNs);\n      userID.setText(\"\");\n      method.addChild(mobileCode);\n      method.addChild(userID);\n      method.build();\n      // 远程调用web服务\n      OMElement result = client.sendReceive(method);\n      System.out.println(result);\n\n注:返回的xml数据可能含有需要转义的字符,比如&amp;lt;之类的.\n可以用org.apache.commons.lang3.StringEscapeUtils.unescapeXml方法处理,(已过时),\n可以用commons-text包下的StringEscapeUtils类进行反转义处理\n\n2.wsdl2java 方式调用  使用 jdk 命令行下的 wsimport 命令和 wsdl 文件生成生成客户端中间代码，\n  注意：只能编译 soap1.1 的协议，不能编译 soap1.2 的协议的代码\nwsimport [options] &lt;WSDL_URI&gt;\n比较常用的[options]有：\n1. -d &lt;directory&gt;\n  在指定的目录生成class文件\n2. -clientjar &lt;jarfile&gt;\n  在当前目录生成jar文件，结合-d &lt;directory&gt;可以在指定的目录生成jar文件\n3. -s &lt;directory&gt;\n  在指定的目录生成java源文件\n4. -p &lt;pkg&gt;\n  指定生成文件的包结构\n5. -keep\n  在生成class文件，或者jar包时，同时保留java源文件\n\n例：在当前目录新建 class 文件夹和 java 文件夹，分别存放对应的 class 文件个 java 文件\nwsimport -keep -d ./class -s ./java -p com.test.demo -verbose http://ws.webxml.com.cn/WebServices/MobileCodeWS.asmx?wsdl  \n\n//创建一个MobileCodeWS工厂  \nMobileCodeWS factory = new MobileCodeWS();  \n//根据工厂创建一个MobileCodeWSSoap对象  \nMobileCodeWSSoap mobileCodeWSSoap = factory.getMobileCodeWSSoap();  \n//调用WebService提供的getMobileCodeInfo方法查询手机号码的归属地  \nString searchResult = mobileCodeWSSoap.getMobileCodeInfo(\"18265963256\", null);  \nSystem.out.println(searchResult);  \n\n笔后摘要:\nwebservice 既然是基于 http 的，那么也可使用最原始的 URLconnect 来进行访问请求处理，但是要注意对应的 soap 协议版本请求头，还需要组装符合 soap 协议 xml 文档信息等。完整的请求头应该和下例类似:\n  请求头:\n  POST /WebServices/MobileCodeWS.asmx HTTP/1.1\n  Host: webservice.webxml.com.cn\n  Content-Type: text/xml; charset=utf-8\n  Content-Length: length\n  SOAPAction: \"http://WebXml.com.cn/getMobileCodeInfo\"\n\n消息体:\n&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n&lt;soap:Envelope xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:soap=\"http://schemas.xmlsoap.org/soap/envelope/\"&gt;\n&lt;soap:Body&gt;\n&lt;getMobileCodeInfo xmlns=\"http://WebXml.com.cn/\"&gt;\n&lt;mobileCode&gt;18265963256&lt;/mobileCode&gt;\n&lt;userID&gt;string&lt;/userID&gt;\n&lt;/getMobileCodeInfo&gt;\n&lt;/soap:Body&gt;\n&lt;/soap:Envelope&gt;","tags":["java","axis2","WebService"]},{"title":"debian 系系统编译 CuraEngine 引擎","url":"/debian%E7%B3%BB%E7%B3%BB%E7%BB%9F%E7%BC%96%E8%AF%91CuraEngine%E5%BC%95%E6%93%8E/","content":"  摘要:CuraEngine是一个功能强大、快速、强劲的3D模型切片引擎.Cura就是采用了CuraEngine引擎的.\n  本文的操作环境为deepin 15.7,编译CuraEngine的版本为2.4\n\n1. 安装 cmake\nsudo apt install cmake\n\n2. 安装 Protobuf &gt;= 3.0.0 \n  2.1 安装 libtool\nsudo apt install libtool\n\n  2.2 安装 autoconf\nsudo apt install autoconf\n\n  2.3 clone 代码，–depth=1.clone 最近一次提交的，可以减少 clone 时间\ngit clone https://github.com/protocolbuffers/protobuf.git --depth=1\n\n  2.4 进入到 protobuf 目录。执行\n./autogen.sh\n\n  2.5 \n./configure\n\n  2.6 \nmake \n\n  2.7 \nsudo make install\n\n3. 安装 libArcus\n  3.1 安装 python3-dev\n  sudo apt install python3-dev\n\n  3.2 安装 python3-sip-dev\nsudo apt install python3-sip-dev\n\n  3.3 安装 libprotobuf-dev\nsudo apt install libprotobuf-dev\n\n  3.4 clone 代码\ngit clone https://github.com/Ultimaker/libArcus.git --depth=1\n\n  3.5 进入到 libArcus 目录，执行\nmkdir build &amp;&amp; cd build\ncmake ..\n\n  3.6 \nmake\n\n  3.7 \nsudo make install\n\n4. 编译 CuraEngine\n  4.1 clone 代码。此处编译 2.4 版本，-b 指定版本\ngit clone https://github.com/Ultimaker/CuraEngine.git -b 2.4 --depth=1\n\n  4.2 \nmkdir build &amp;&amp; cd build\n\n  4.3 \ncmake ..\n\n  4.4 \nmake\n\n","tags":["linux"]},{"title":"deepin linux 下初识 docker","url":"/deepin-linux%E4%B8%8B%E5%88%9D%E8%AF%86docker/","content":"deepin linux 安装最新版 docker可以参考官放 wiki 文档进行安装，地址如下:\nhttps://wiki.deepin.org/wiki/Docker#.E5.9C.A8_Deepin_.E4.B8.AD.E5.AE.89.E8.A3.85_Docker_.E6.9C.80.E6.96.B0.E7.89.88.E7.9A.84.E6.96.B9.E6.B3.95\n但官网打开速度比较慢，另外关于最后一项禁止开启自启官方说的方式是无效的，笔者亲试至少在 (deepin 15.10.1 基于 unstable 升级上来的) 是无效的。所以将详情步骤记录如下:\n注:执行apt命令之前,最好先执行一次更新仓库操作sudo apt update\n\n1. 如果以前安装过老版本，要确保先卸载以前版本.\nsudo apt remove docker.io docker-engine\n2. 安装密钥管理与下载相关的工具\n// 密钥管理（add-apt-repository ca-certificates 等）与下载（curl 等）相关的工具\nsudo apt-get install apt-transport-https ca-certificates curl python-software-properties software-properties-common\n3. 下载并安装密钥\ncurl -fsSL https://download.docker.com/linux/debian/gpg | sudo apt-key add -\n执行成功后返回 OK 即可。如果不成功的话，可能是网络问题，我这儿是处于翻墙状态，所以是能成功的。不能成功的话，可以按照官方 wiki 上说的使用国内镜像源 curl -fsSL https://mirrors.ustc.edu.cn/docker-ce/linux/debian/gpg | sudo apt-key add -\n4. 查看密钥是否安装成功\nsudo apt-get fingerprint 0EBFCD88\n如果成功会提示\npub 4096R/0EBFCD88 2017-02-22 Key fingerprint = 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88uid Docker Release (CE deb) &lt;docker@docker.com&gt;sub 4096R/F273FCD8 2017-02-22\n5. 在 source.list 中添加 docker-ce 软件源\n在此需要注意当前系统版本,执行 cat /etc/debian_version查看当前系统是基于debian的哪个版本.debian版本号和系统代号如下:\n\n\n\n\n系统代号\n版本号\n\n\n\n squeeze\n6.x\n\n\nwheezy\n7.x\n\n\njessie\n8.x\n\n\nstretch\n9.x\n\n\ndeepin 15.10.x 是基于 debian9.0 的，所以加入源如下:\nsudo vim /etc/apt/sources.list\ndeb [arch=amd64] https://mirrors.ustc.edu.cn/docker-ce/linux/debian stretch stable\n6. 更新仓库\nsudo apt update\n7. 安装 docker-ce\nsudo apt install docker-ce\n注:这一步网络不好可能会导致失败,多试几次总会成功的.\n\n8. 启动 docker\nsudo systemctl start docker 或者service docker start\n9. 查看安装的版本信息\ndocker version\n10. 验证 docker 是否被正确安装并且能够正常使用\nsudo docker run hello-world\n如果能够正常下载，并能够正常执行，则说明 docker 正常安装\n11. 让普通用户也能运行 docker\n默认情况下，普通用户运行 docker 会有权限问题，每次运行都得加 sudo，很麻烦。把你的账号加到 docker 用户组后就不用加 sudo 了：\n\nsudo usermod -aG docker test //test 是用户名，替换为自己的，执行后注销登录\n12.docker service 默认是开机自启的，强迫症取消开机自启的\n这一点,官方说的安装chkconfig来管理\n\n安装 chkconfig\nsudo apt install chkconfig\n移除自启\nsudo chkconfig --del docker\n但是试了,重启无效无效.需要通过systemctl命令来禁止\n\nsudo systemctl disable docker\ndocker 使用初识docker 入门命令docker 安装后，默认是没有任何镜像的，如果安装后执行了 docker run hello-world 的话，是有一个 hello-world 的镜像的.\ndocker images // 查看本地的镜像\n可以通过 pull 命令获取相关镜像\ndocker search nginx // 在 docker.io 上搜索 nginx 相关的镜像\ndocker pull nginx:latest //latest 代表取最新版本，要获取其他版本 docker pull nginx:xxxx\ndocker run -itd --name nginx1.0 nginx //-d: 后台启动容器；-i: 以交互模式运行容器，通常与 -t 同时使用；-t: 为容器重新分配一个伪输入终端，通常与 -i 同时使用；–name：容器的别名，默认为随机的，这儿为 nginx1.0\n第一次使用run运行指定别名后,以后可通过docker start+ 别名的方式启动\n\ndocker ps // 查看正在运行的容器\ndocker ps -a // 查看所有容器\ndocker ps -l // 查看最近一次运行的容器\ndocker exec -it nginx1.0 bash // 进入 nginx1.0 容器的命令行\ndocker start nginx1.0 // 启动 nginx1.0 容器\ndocker stop nginx1.0 // 停止 nginx1.0 容器\ndocker rm nginx1.0 // 删除 nginx1.0 容器\ndocker 网络linux 使用 namespace 来进行资源的隔离 ，docker 的隔离性\n1.docker 的网路类型分为：\nBridge 模式：桥接（默认的模式）\nhost 模式：容器将不会获得独立的 network namespace，将和主机公用一个；即在 docker 中使用网络和主机上一样的；\nNone：不与外界任何东西进行通讯\n2. 采用 Bridge 的时候需要和主机通讯，就需要使用端口映射\ndocker run -d –name nginx1.0 -p 8080:80 nginx # 主机的 8080 端口映射到容器中的 80 端口\n多个端口映射可以跟多个-p,比如:-p 8080:80 -p 6379:6379\n\ndocker 镜像备份和导入镜像docker save -o /home/xxx/images/nginx.tar nginx1.0 // 将 nginx1.0 镜像备份到 /home/xxx/images/ 目录下\ndocker load --input /home/xxx/images/nginx.tar // 导入镜像\ndocker 挂载物理机本地目录docker 可以支持把一个宿主机上的目录挂载到镜像里。\ndocker run -itd -v /home/bz/Downloads:/home/Downloads nginx1.0 // 通过 - v 参数，冒号前为宿主机目录，必须为绝对路径，冒号后为镜像内挂载的路径\n默认挂载的路径权限为读写。如果指定为只读可以用：ro\ndocker run -itd -v /home/bz/Downloads:/home/Downloads:ro nginx1.0\n","tags":["linux","docker"]},{"title":"atom 配置 vue 前端开发环境","url":"/atom%E9%85%8D%E7%BD%AEvue%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/","content":"1. 安装好 atom 后，安装常用的几个插件\nprettier-atom : 格式化代码插件\n\natom-axios : vue-axios提示插件\n\nautoclose-html : 自定补全闭合html标签插件\n\nfile-icons : 文件图标,便利区分不同类型的文件\n\nautocomplete-paths : 自动提示补全文件路径插件\n\nlanguage-vue : atom支持vue的插件\n\nlanguage-vue-component : 高亮显示vue组件插件\n\nvue2-autocomplete : vue2.0+提示插件\n\nlinter-eslint : eslint规则校验插件\n\npx2rem-plus : px转rem插件\n\nminimap : 在编辑器右边出现预览源代码(类似sublime text3右侧预览导航效果)的插件\n\n下面是支持markdown的插件:\n\nmarkdown-toc : 对markdown文档生成目录的插件\n\nmarkdown-table-editor : markdown文档表格编辑插件\n\n2. 安装好对应的插件后，大部分情况能够使用，但是 vue 项目需要支持 eslint 校验的话，需要对 linter-eslint 设置下面的 Lint-HTML-Files 进行勾选\n\n3. 默认的 prettier 格式化的规则是不符合 eslint 的，比如会对每行尾部增加分号，单引号变变为双引号，需要修改其配置为下:\n\n","tags":["atom"]},{"title":"git 常用的使用总结","url":"/git%E5%B8%B8%E7%94%A8%E7%9A%84%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/","content":"对一个已存在的远程仓库进行 clone 和提交代码操作clone 代码\n\n$ git clone [-b branchName] 远程地址 [filefolder name]\n\n\n-b 代表 clone 某个分支，后面跟分支的名称。代码 clone 到本地后，当前路径会多一个与 git 远程项目名相同的文件夹 (手工指定文件夹名除外).\n\n\n$ cd 文件夹名\n\n提交代码:\n\n$ git status // 查看当前工作目录的状态\n\n\n$ git add . 或 git add -u 或 git add -A (git add –all 的缩写) // 添加要提交的文件到 git 暂存区。相关区别：三条命令对应的 git 版本不一样也有区别.\n\n\ngit1.x 版本\n\n\ngit2.x 版本\n\n\n使用 2.x 以上版本的 git 使用 - a 和。是一样的。本人通常使用。更加方便快捷\n\n\n$ git status // 添加文件到暂存区后再次查看确保文件的状态\n\n\n$ git commit -m “注释”\n\n\n$ git remote -v // 查看当前已经存在的 git 远程 url\n\n\n$ git push -u 远程名称 本地要提交的分支：远程分支 // 远程分支不存在的时候会自动在远程创建该名称分支\n\n已有代码在用户本地，远程不存在的情况\n$ cd existing_folder\n\n\n$ git init\n\n\n$ git status\n\n\n$ git remote add origin git@code.aliyun.com:baz/foo.git\n\n\n$ git add .\n\n\n$ git status\n\n\n$ git commit -m “注释”\n\n\n$ git push -u origin master:master // 提交本地 master 到远程 master\n\n对远程初始化仓库有 git history, 本地代码也有 git history 的情况\n针对远程本地都有 git 提交的情况，比较特殊。比如阿里云 code 上面新建项目必须选择对应的模板，会进行对仓库初始化操作。而本地存在之前的项目 (已经含有 git 记录，比如 gitlab,coding 之类的). 推荐方式：先从远程 clone 下来。然后删除 clone 下来的文件夹下的文件 (.git 目录除外). 然后 commit-&gt;push 提交到远程\n\n1. 删除远程仓库不需要的文件\n\n$ git clone alicodeurl xxx\n\n\n$ cd xxx\n\n\n// 去资源文件管理器中手动删除除.git 目录外的其他文件. linux/osx 也可 cd 目录再 rm 删除\n\n\n$ git status\n\n\n$ git add .\n\n\n$ git status\n\n\n$ git commit -m “注释”\n\n\n$ git push -u origin master:master // 提交本地 master 到远程 master\n\n2. 对本地项目进行提交到远程\n\n$ cd project filefolder\n\n\n$ git remote add origin git@code.aliyun.com:baz/foo.git\n\n\n$ git pull origin master –allow-unrelated-histories // 会弹出 merge 的编辑器，删除或者增加内容后退出\n\n\n$ git add .\n\n\n$ git commit -m “注释”\n\n\n$ git push -u origin master:master // 提交本地 master 到远程 master\n\n项目开发中的分支使用切换分支\n\n$ git checkout 分支名称\n\n创建分支 dev\n\n$ git checkout -b dev  // 创建并进入到分支，git branch 可查看当前分支指针状态\n\n注约定在 Dev 分支上面进行编码开发。上述的所有提交代码命令必须在 dev 分支上执行，最后的一句 git push 换成以下命令\n\n$ git push -u origin dev:dev // 提交本地 dev 到远程 dev. 第一次远程无 dev 会自动创建 dev\n\n更新远程分支代码到本地:\n\n$ git fetch origin dev //fetch 远程 dev 分支代码 .. 避免使用 pull\n\n在当前分支合并 fetch 下面的代码\n\n$ git merge origin/dev  // 合并从远程 dev 分支 fetch 下来的代码\n\n注意版本正式上线后，需要将 dev 分支发布到 Master 分支。采用以下命令:\n\n$ git checkout master  // 切换到 Master 分支\n\n\n$ git merge –no-ff dev // 对 Dev 分支进行合并\n\n\n使用–no-ff 参数后，会执行正常合并，在 Master 分支上生成一个新节点。为了保证版本演进的清晰，推荐采用这种做法\n\nGit4 个阶段的撤销操作\n了解 git 阶段首选理解 git 的几个区:\n\n\n工作区 (working area),\n\n\n暂存区 (stage),\n\n\n本地仓库 (local repository),\n\n\n远程仓库 (remote repository).\n\n\n每将文件存到不同的区的时候会产生一个状态，在加上最开始的一个状态总共 5 个状态.\n\n\n未修改 (Origin)\n\n\n已修改 (Modified)\n\n\n已暂存 (Staged)\n\n\n已提交 (Committed)\n\n\n已推送 (Pushed)\n\n1. 文件处于已修改的状态，即修改过文件。未暂存 (add)\n文件已修改，恢复到初始状态 (未做任何修改状态)\n\n\n$git checkout . 或者 $git reset –hard origin/dev    // 恢复到与远程 dev 保持一致的状态，相当于刚 clone dev 的状态\n\n2. 文件处于已暂存 (stage), 未提交 (commit)\n文件已经进行过 git add . 操作，但是还未进行 git commit 操作\n\n\n$git reset  // 恢复到已修改的状态\n\n\n$git checkout . // 继续执行这条，就恢复到初始状态 (未做任何修改状态)\n\n\n如果要实现恢复到初始状态 (未做任何修改状态), 除了通过执行上面 2 步命令外，也可一直接执行下面这句，一步恢复到初始状态\n\n\n$git reset –hard // 一步到初始状态\n\n3. 文件处于已提交 (commit), 未推送 (push)\n这种情况下，代表已经提交到本地仓库了，既然已经污染了你的本地仓库，那么就从远程仓库把代码取回来吧。恢复到初始状态了，\n\n\n$git reset –hard origin/dev  // 直接恢复到初始化状态，但已做的修改全部会丢失\n\n4. 文件处于已推送 (push)\n既 git add 了，又 git commit 了，并且还 git push 了，这时代码已经进入远程仓库。如果想恢复的话。由于本地仓库和远程仓库是等价的，只需要先恢复本地仓库，再强制 push 到远程仓库就好了\n\n\n$git reset –hard HEAD^   // 将本地恢复到初始状态，之前已做的修改全部会丢失\n\n\n$git push -f // 将本地仓库初始化后推送到远程，将远程保持和本地一致\n\n注：只要还未影响到本地仓库 (local repository) 的时候，即没有 commit 时，都可以恢复到已修改的状态。一旦 commit 后，影响了本地仓库，就只能恢复到上一次的本地仓库的版本。所做的修改都会丢失..###git 撤销暂存区的文件\n\n有时候执行 git add . 后，将当前目录下的所有改动文件都添加到了暂存区，此时如果有三两个文件是不需要添加进暂存区的，可以执行以下命令将文件从暂存区移除$git rm –cached 文件名\n\ngit tag 的常用使用\nGit 可以对某个版本打上标签 (tag)，表示本版本为发行版\n\n\n$git tag // 查看所有标签\n\n\n$git tag -l 1.0.*  // 打印符合检索条件的标签\n\n\n$git checkout 1.0.0 // 查看对应标签状态\n\n\n$git tag -a 1.0.0 -m “1.0.0 版本” // 创建带备注标签 (推荐)\n\n\n$git tag -a 1.0.0 0c3b62d -m “备注信息” // 针对特定 commit 版本 SHA 创建标签\n\n\n$git tag -d 1.0.0 // 删除本地 1.0.0 标签\n\n\n$git push origin –tags // 将本地所有标签发布到远程仓库\n\n\n$git push origin 1.0.0 // 指定标签版本 (1.0.0) 发送\n\n\n$git push origin –delete 1.0.0 // 删除远程仓库对应标签，此命令需要 Git 版本 &gt; V1.7.0\n\n\n$git push origin :refs/tags/1.0.0 // 删除远程仓库对应标签，此命令需要 Git 版本 &lt; V1.7.0\n\n","tags":["Git"]},{"title":"jsp 訪問 API 報錯 PKIX path building failed，JAVA 添加信任 SSL 證書","url":"/jsp%E8%A8%AA%E5%95%8FAPI%E5%A0%B1%E9%8C%AFPKIX%20path%20building%20failed%EF%BC%8CJAVA%E6%B7%BB%E5%8A%A0%E4%BF%A1%E4%BB%BBSSL%E8%AD%89%E6%9B%B8/","content":"jsp 訪問 API 報錯 PKIX path building failed，JAVA 添加信任 SSL 證書問題JSP訪問API時，報錯PKIX path building failed\n\n原因HTTPS域名的SSL Certification 不在 JDK/JRE 的證書庫中,被JAVA認為是不可信的HTTPS域名。\n\n解決辦法下載目標地址的證書通過瀏覽器打開API,在地址欄 \"HTTPS\" 旁邊點擊按鈕,彈出相關證書信息窗口。\n\n通過Export，得到後綴為 .crt 的 base64 證書文件。(如可選請選擇base64)\n\n找到 JAVA 安裝目錄（即 JAVA_HOME）e.g. C:\\Program Files\\Java\\jdk-21\n找到證書庫存放位置證書庫存放在 `%JAVA_HOME%\\lib\\security` 下，一個名為 `cacerts` 的文件\n\n記錄路徑：`\"C:\\Program Files\\Java\\jdk-21\\lib\\security\\cacerts\"`\n\n找到目標地址下載的證書位置e.g. \"C:\\Users\\ArHay\\Downloads\\example.crt\"\n使用命令行註冊 Certification 到證書庫\n進入 \"C:\\Program Files\\Java\\jdk-21\\bin\" 文件夾\n(若已經配置全局變量 %JAVA_HOME%, 可以忽略該步驟)\n\n使用命令 keytool 註冊證書\n keytool -import -alias example -keystore \"C:\\Program Files\\Java\\jdk-21\\lib\\security\\cacerts\" -file \"C:\\Users\\ArHay\\Downloads\\example.crt\"\n\n輸入兩次密碼\nchangeit\n\n結果再次嘗試訪問 API，無報錯，正常返回。問題解決。\n","tags":["jsp","SSL","Certification","JAVA"]},{"title":"linux 下 nginx 部署配置多站点","url":"/linux%E4%B8%8Bnginx%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E5%A4%9A%E7%AB%99%E7%82%B9/","content":"摘要:\n  有时候你想在一台服务器上为不同的域名运行不同的站点。\n  比如www.siteA.com作为博客，www.siteB.com作为论坛。你可以把两个域名的IP都解析到你的服务器上，\n  但是没法在Nginx的根目录里同时运行两个不同的网站.\n  这时可以在nginx上面配置部署多个站点(使用nginx虚拟目录),为你节省服务器费用.\n  假设你把博客放在”/home/user/www/blog”下，论坛放在”/home/user/www/forum”下。下面我们就开始进行配置:\n\n1. 在 Nginx 配置目录下，创建一个”vhost” 目录。本例假设 Nginx 是默认安装，配置目录在”/etc/nginx”\nsudo mkdir /etc/nginx/vhost #创建保存站点配置文件的目录\n2. 创建 siteA 的配置文件\n‘sudo vim /etc/nginx/vhost/siteA.conf #打开该文件 (没有的话保存后会自动新建)’\n在文件里面输入以下配置内容 (具体的相关目录及 location 内容根据自己实际情况修改，下面只是 nginx 配置文件的基本结构，其实可以拷贝 nginx 自带的配置文件到 vhost 目录下，然后对文件内容进行修改):\nserver {\n  listen 80; # 监听端口\n  server_name www.siteA.com siteA.com; # 站点域名\n  root /home/user/www/blog; # 站点根目录\n  index index.html index.htm index.php; # 默认导航页\n\n  #rewrite ^(.*) https://$host$1 permanent; #重定向到https\n\n  location / {\n    # WordPress固定链接URL重写\n    if (!-e $request_filename) {\n      rewrite (.*) /index.php;\n    }\n  }\n  location / {\n    # WordPress固定链接URL重写\n    if (!-e $request_filename) {\n      rewrite (.*) /index.php;\n    }\n  }\n  location ^~ /device/ {\n\t  proxy_pass http://127.0.0.1:8080;\n  }\n  location ^~ /upload/ {  \n    root  /aaa/bbb;\n    expires   7d;\n  }\n}\n\n3. 跟第二步一样，创建 siteB 的配置文件.(“server_name” 和”root” 目录的内容和 siteA 不同)\n‘sudo vim /etc/nginx/vhost/siteB.conf #打开该文件 (没有的话保存后会自动新建)’\n在文件里面输入以下配置内容 (具体的相关目录及 location 内容根据自己实际情况修改，下面只是 nginx 配置文件的基本结构，其实可以拷贝 nginx 自带的配置文件到 vhost 目录下，然后对文件内容进行修改):\nserver {\n  listen 80; # 监听端口\n  server_name www.siteB.com siteB.com; # 站点域名\n  root /home/user/www/blog; # 站点根目录\n  index index.html index.htm index.php; # 默认导航页\n\n  #rewrite ^(.*) https://$host$1 permanent; #重定向到https\n\n  location / {\n    # WordPress固定链接URL重写\n    if (!-e $request_filename) {\n      rewrite (.*) /index.php;\n    }\n  }\n  location ^~ /device/ {\n\t  proxy_pass http://127.0.0.1:8080;\n  }\n  location ^~ /upload/ {  \n    root  /aaa/bbb;\n    expires   7d;\n  }\n  # websocket地址\n  location ^~ /ws {\n\t    proxy_pass http://127.0.0.1:10002;\n    }\n}\n\n4. 打开编辑 nginx 的配置文件\nsudo vim /etc/nginx/nginx.conf\n将我们第一步创建的虚拟目录的路径增加到 nginx.conf 文件中去，将下面的内容加入到”http {}” 部分的末尾\nhttp {\n  ...\n  include /etc/nginx/vhost/*.conf;\n}\n\n5. 重启 nginx 服务 (注意：所有的配置文件修改保存后，先不急重新加载配置，先使用 nginx -t 测试下文件内容是否有错在进行重新加载配置操作)\nsudo service nginx restart\n6. 访问 www.siteA.com 和 www.siteB.com，你将发现浏览器会打开不同的站点\nnginx 禁止 ip 访问的小技巧:\n假如你的 Nginx 根目录设在”/home/user/www”，你想阻止别人通过”http://IP 地址 /blog” 或”http://IP 地址 /forum” 来访问你的站点，最简单的方法就是禁止 IP 地址访问。方法如下：\n打开 Nginx 网站默认配置文件，记得先备份\nsudo cp /etc/nginx/sites-available/default /etc/nginx/sites-available/default_bak #备份原来的默认文件\nsudo vim /etc/nginx/sites-available/default #编辑文件\n将其所有内容删除，只留以下配置\nserver {\n  listen 80 default_server;\n  server_name _;\n  return 404;\n}\n\n然后重启 nginx 或者 nginx -s reload 使配置文件生效，别人将无法通过 IP 地址访问网站了\n如果你不想禁止 IP 地址访问整个目录，只是要防止别人通过 IP 访问你的博客和论坛。那就需要禁止”/blog” 和”/forum” 的目录访问\n打开 Nginx 网站默认配置文件，同上面一样，记得先备份一下\n在”server {}” 节点的部分加上以下配置，然后重启 nginx 或者 reload nginx 配置即可.\nlocation ^~ /blog/ {\n  deny all;\n}\nlocation ^~ /forum/ {\n  deny all;\n}\n\n7.nginx 常用的配置选项模板    /etc/nginx/nginx.conf\nhttp {\n  sendfile on;\n  tcp_nopush on;\n  tcp_nodelay on;\n  keepalive_timeout 65;\n  types_hash_max_size 2048;\n  server_tokens off; # 关闭nginx版本标识\n\n  underscores_in_headers on; #自定义Header中含有下划线的情况 必须定义\n  gzip  on;\n  gzip_min_length 1k;\n  gzip_buffers 16 64k;\n  gzip_http_version 1.1;\n  gzip_comp_level 6;\n  gzip_types text/plain application/javascript application/x-javascript text/css application/xml text/javascript application/x-httpd-php image/jpeg image/gif image/png;\n  gzip_vary on;\n  gzip_disable \"MSIE [1-6]\\.\";\n\n  #proxy_connect_timeout 600;  #nginx跟后端服务器连接超时时间(代理连接超时)\n  \n  proxy_buffer_size     32k;  #设置代理服务器（nginx）保存用户头信息的缓冲区大小\n  proxy_buffers         4 32k;#proxy_buffers缓冲区，网页平均在32k以下的话，这样设置\n  proxy_busy_buffers_size  64k;           #高负荷下缓冲大小（proxy_buffers*2）\n  proxy_temp_file_write_size  1024m;       #设定缓存文件夹大小，大于这个值，将从upstream服务器传\n  client_max_body_size 100M;\n\n  # 给后端服务器暴露获取客户端真实IP地址的头\n  proxy_set_header X-Real-IP $remote_addr;\n  proxy_set_header REMOTE-HOST $remote_addr;\n  proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n\n  # websocket 支持\n  proxy_http_version 1.1;\n  proxy_set_header Upgrade $http_upgrade;\n  proxy_set_header Connection \"upgrade\";\n  proxy_read_timeout    600;  #连接成功后，后端服务器响应时间(代理接收超时)\n  proxy_send_timeout    600;  #后端服务器数据回传时间(代理发送超时)\n}\n\n8. 站点配置文件样例，例如:/etc/nginx/vhost/a.conf\nserver {\n  listen          80;\n  server_name     www.aaa.com  aaa.com;\n  root            /opt/pages/;\n  index           index.html index.htm;\n\n  # Cookie的HttpOnly属性，指示浏览器不要在除HTTP（和HTTPS)请求之外暴露Cookie。一个有HttpOnly属性的Cookie，是不可以通过例如调用JavaScript(引用document.cookie)这种非HTTP方式来访问。因此，也不可能通过跨域脚本（一种非常普通的攻击技术）来偷走这种Cookie。\n  add_header                  Set-Cookie \"HttpOnly\";\n  # Cookie的Secure属性，意味着保持Cookie通信只限于加密传输，指示浏览器仅仅在通过安全/加密连接才能使用该Cookie。如果一个Web服务器从一个非安全连接里设置了一个带有secure属性的Cookie，当Cookie被发送到客户端时，它仍然能通过中间人攻击来拦截\n  add_header                  Set-Cookie \"Secure\";\n  # X-Frame-Options HTTP 响应头是用来给浏览器指示允许一个页面可否在 &lt;frame&gt;, &lt;iframe&gt; 或者 &lt;object&gt; 中展现的标记。网站可以使用此功能，来确保自己网站的内容没有被嵌到别人的网站中去，也从而避免了点击劫持 (clickjacking) 的攻击。它有三个可选择项：(DENY：表示该页面不允许在 frame 中展示，即便是在相同域名的页面中嵌套也不允许；SAMEORIGIN：表示该页面可以在相同域名页面的 frame 中展示；ALLOW-FROM uri地址：表示该页面可以在指定来源的 frame 中展示；)\n  add_header                  X-Frame-Options \"SAMEORIGIN\";\n\n  # 禁用OPTIONS TRACE不安全方法,屏蔽GET、POST、之外的HTTP方法\n  if ($request_method !~* GET|POST) {\n      return 403;\n  }\n\n  # 跨域配置\n  location / {\n    add_header Access-Control-Allow-Origin *;\n    add_header Access-Control-Allow-Methods 'GET, POST, OPTIONS';\n    add_header Access-Control-Allow-Headers 'DNT,X-Mx-ReqToken,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization';\n\n    if ($request_method = 'OPTIONS') {\n      return 204;\n    }\n  }\n\n  # 转发以/api/开头的请求\n  location ^~ /api/ {\n    proxy_pass http://127.0.0.1:8080;\n  }\n\n  # 以/upload开头的请求\n  location ^~ /upload/ {\n    root  /opt/dir/;\n    expires   7d;\n  }\n}\n\n9.nginx 负载均衡配置\n  在 http 节点下配置服务器列表\nhttp {\n  # upstream模块：配置反向代理服务器组，Nginx会根据配置，将请求分发给组里的某一台服务器。serverGroup是服务器组的名称.\n  upstream serverGroup {\n    server 192.168.0.100:8080;\n    server 192.168.0.101:8080;\n  }\n  # serverGroup内部的server指令：配置处理请求的服务器IP或域名，端口可选，不配置默认使用80端口。通过上面的配置(默认的是轮询策略,把每个请求逐一分配到不同的server，如果分配到的server不可用，则分配到下一个，直到可用)，Nginx默认将请求依次分配给100，101来处理，可以通过修改下面这些参数来改变默认的分配策略：\n\n  1.weight权重,默认为1，将请求平均分配给每台server.值越大，则被访问的概率越大.下面标示101访问数量是100的2倍\n  upstream serverGroup {\n    server 192.168.0.100:8080 weight=1;\n    server 192.168.0.101:8080 weight=2 max_fails=3 fail_timeout=15;\n    server 192.168.0.102:8080 down; #down 表示当前服务器不参与负载均衡，也就是说不会被访问到\n    server 192.168.0.103:8080 backup; #backup 表示备份机，所有服务器挂了之后才会生效\n  }\n  max_fails:默认为1。某台Server允许请求失败的次数，超过最大次数后，在fail_timeout时间内，新的请求将不会分配给这台机器。如果设置为0，Nginx会将这台Server置为永久无效状态，然后将请求发给定义了proxy_next_upstream fastcgi_next_upstream, uwsgi_next_upstream, scgi_next_upstream, and memcached_next_upstream指令来处理这次错误的请求\n  fail_timeout:默认为10秒。某台Server达到max_fails次失败请求后，在fail_timeout期间内，nginx会认为这台Server暂时不可用，不会将请求分配给它\n\n  2.最少连接,把请求分配到连接数最少的server\n  upstream serverGroup {\n    least_conn;\n    server 192.168.0.100:8080;\n    server 192.168.0.101:8080;\n  }\n\n  3.ip_hash,根据访问客户端ip的hash值分配，这样同一客户端的请求都会被分配到同一个server上，如果牵扯到session的问题，用这个是最好的选择\n  upstream serverGroup {\n    ip_hash;\n    server 192.168.0.100:8080;\n    server 192.168.0.101:8080;\n  }\n}\n\n  在 server 节点下配置 proxy_pass\nserver {\n    listen  80;\n    server_name serverGroup;\n    location / {\n      proxy_pass   http://serverGroup; # 表示将所有请求转发到tomcats服务器组中配置的某一台服务器上\n    }\n}\n\n","tags":["linux","nginx"]},{"title":"java 实现图片的灰度化处理","url":"/java%E5%AE%9E%E7%8E%B0%E5%9B%BE%E7%89%87%E7%9A%84%E7%81%B0%E5%BA%A6%E5%8C%96%E5%A4%84%E7%90%86/","content":"摘要:24位彩色图与8位灰度图\n\n在一个24位彩色图像中，每个像素由三个字节表示，通常表示为RGB。\n通常，许多24位彩色图像存储为32位图像，每个像素多余的字节存储为一个alpha值，表现有特殊影响的信息\n在RGB模型中，如果R=G=B时，则彩色表示一种灰度颜色，其中R=G=B的值叫灰度值，\n因此，灰度图像每个像素只需一个字节存放灰度值（又称强度值、亮度值），灰度范围为0-255.\n这样就得到一幅图片的灰度图\n\n常见的几种灰度化的方法:\n分量法：使用RGB三个分量中的一个作为灰度图的灰度值。\n最值法：使用RGB三个分量中最大值或最小值作为灰度图的灰度值。\n均值法：使用RGB三个分量的平均值作为灰度图的灰度值。\n加权法：由于人眼颜色敏感度不同，按下一定的权值对RGB三分量进行加权平均能得到较合理的灰度图像。\n一般情况按照：Y = 0.30R + 0.59G + 0.11B.加权法实际上是取一幅图片的亮度值\n人眼对绿色的敏感最高，对蓝色敏感最低 ）作为灰度值来计算，用到了YUV模型\n\njava 编码实现图片灰度化\n1. 强制设置灰度化的方法（效果相对就差）\n/**\n * 图片灰化（效果不行，不建议。据说：搜索“Java实现灰度化”，十有八九都是一种方法）\n *\n * @param bufferedImage 待处理图片\n * @return\n * @throws Exception\n */\npublic static BufferedImage grayImage(BufferedImage bufferedImage) throws Exception {\n\n    int width = bufferedImage.getWidth();  \n    int height = bufferedImage.getHeight();  \n\n    BufferedImage grayBufferedImage = new BufferedImage(width, height,\n                                    BufferedImage.TYPE_BYTE_GRAY);\n    for (int x = 0; x &lt; width; x++) {  \n        for(int y = 0 ; y &lt; height; y++) {  \n        \tgrayBufferedImage.setRGB(x, y, bufferedImage.getRGB(x, j));  \n        }  \n    }  \n}\n\n2. 加权法灰度化（效果较好）\n/**\n * 图片灰化（参考：http://www.codeceo.com/article/java-image-gray.html）\n *\n * @param bufferedImage 待处理图片\n * @return\n * @throws Exception\n */\npublic static BufferedImage grayImage(BufferedImage bufferedImage) throws\n  Exception {\n\tint width = bufferedImage.getWidth();\n\tint height = bufferedImage.getHeight();\n\tBufferedImage grayBufferedImage = new BufferedImage(width, height,\n                                    BufferedImage.TYPE_BYTE_GRAY);\n\tfor (int x = 0; x &lt; width; x++) {\n\t\tfor (int y = 0; y &lt; height; y++) {\n\t\t\t// 计算灰度值\n\t\t\tfinal int color = bufferedImage.getRGB(x, y);\n\t\t\tfinal int r = (color &gt;&gt; 16) &amp; 0xff;\n\t\t\tfinal int g = (color &gt;&gt; 8) &amp; 0xff;\n\t\t\tfinal int b = color &amp; 0xff;\n\t\t\tint gray = (int) (0.3 * r + 0.59 * g + 0.11 * b);\n\t\t\tint newPixel = colorToRGB(255, gray, gray, gray);\n\t\t\tgrayBufferedImage.setRGB(x, y, newPixel);\n\t\t}\n\t}\n\treturn grayBufferedImage;\n}\n\n/**\n * 颜色分量转换为RGB值\n *\n * @param alpha\n * @param red\n * @param green\n * @param blue\n * @return\n */\nprivate static int colorToRGB(int alpha, int red, int green, int blue) {\n\tint newPixel = 0;\n\tnewPixel += alpha;\n\tnewPixel = newPixel &lt;&lt; 8;\n\tnewPixel += red;\n\tnewPixel = newPixel &lt;&lt; 8;\n\tnewPixel += green;\n\tnewPixel = newPixel &lt;&lt; 8;\n\tnewPixel += blue;\n\treturn newPixel;\n}\n\n","tags":["java"]},{"title":"linux 使用 systemd 方式添加开机自动执行脚本","url":"/linux%E4%BD%BF%E7%94%A8systemd%E6%96%B9%E5%BC%8F%E6%B7%BB%E5%8A%A0%E5%BC%80%E6%9C%BA%E8%87%AA%E5%8A%A8%E6%89%A7%E8%A1%8C%E8%84%9A%E6%9C%AC/","content":"\n前段时间在一台公网服务器上搭建了 vpn 服务用来映射内网一台 gitlab 服务器，实现跨网络也能进行代码提交等操作。过程中经过查找网络上的博客文档基本都没啥问题，但是后续使用过程中，发现客户端 (pptp-linux) vpn 连接会自动断开 (大约是晚上的时候), 后面写了一个脚本后台常驻，检测 vpn 是否连接，如果断开则自动重连。但是问题来了，如果服务器关机了然后开机，则不会自动去连接，需要手工执行连接的脚本。于是，查找相关的 systemd 方式实现开机启动执行相关脚本。由于内网服务器默认登录的账户不是 root 身份，所以使用其他小伙伴的建立 /etc/rc.local 文件的方式是未成功。以下是测试能够通过的方式 (我的内网 gitlab 服务器是 Ubuntu18.04.1-server 版，理论上只要使用 systemd 的方式来管理系统服务启动的发行版都可以)\n\n准备好要执行的脚本文件 (auto_conn.sh)#! /bin/sh\nwhile true\npppdNum=`ifconfig | grep ppp0 | wc -l`\ndo echo \"pppdNum = $pppdNum\"\nif [ $pppdNum -le 0 ]\nthen\n      # \n      echo \"vpn is down,waitting for connectting again...\"\n      sleep 10\n      pppdNum_1=`ifconfig | grep ppp0 | wc -l`\n      echo \"pppdNum = $pppdNum_1\"\n      #\n      if [ $pppdNum_1 -ge 1 ]\n      then\n          echo \"vpn has autolly connect success again!\"\n          # xxxxx是sudo执行的密码,每次连接后需要手工添加路由表,不然不能访问到服务器,ppp0是该网卡的名称.可通过ifconfig查看192.168.2.0/24是自己外网vpn服务器给内部电脑分配的内网ip网关前缀\n          echo 'xxxxx' | sudo -S route add -net 192.168.2.0/24 ppp0\n      else\n          echo \"connectting..\"\n          # xxxxx是sudo执行的密码,vpn_name是自定义vpn连接的名称,000.000.000.000是vpn服务器的ip(公网ip),username是vpn登录的用户名,passwd是vpn登录的密码\n          echo 'xxxxxx' | sudo -S pptpsetup --create vpn_name --server 000.000.000.000 --username username --password passwd vpn-only --encrypt --start\n          echo 'c vpn_client' &gt; /var/run/xl2tpd/l2tp-control\n              sleep 10\n          # xxxxx是sudo执行的密码,每次连接后需要手工添加路由表,不然不能访问到服务器,ppp0是该网卡的名称.可通过ifconfig查看192.168.2.0/24是自己外网vpn服务器给内部电脑分配的内网ip网关前缀\n          echo 'xxxxxx' | sudo -S route add -net 192.168.2.0/24 ppp0\n      fi\nfi\nsleep 5\n\ndone\n注: 某条命令需要sudo执行的话,在脚本中可使用echo 'xxxxxx' | sudo -S 的方式,xxxxxx就是对应的密码\n\n然后给脚本添加执行权限.sudo chmod +x\n创建一个 service 文件sudo vim /etc/systemd/system/auto_startVPN.service\n详细内容如下:\n[Unit]\nDescription=自动连接vpn #自定义的简介描述\nAfter=network-online.target.wants #脚本所需要的前置service，可在/etc/systemd/system/下查看\n\n[Service]\nExecStart=/home/xxx/xxx/auto_conn.sh #第一步中的脚本文件路径\n\n[Install]\nWantedBy=multi-user.target\n\nservice 文件一般正常的启动文件主要分成三部分\n[Unit] 段：启动顺序与依赖关系\n[Service] 段：启动行为，如何启动，启动类型\n[Install] 段：定义如何安装这个配置文件，即怎样做到开机启动\n使用 systemctl 命令使能这个服务开机启动sudo systemctl daemon-reload // 重新加载配置文件\nsudo systemctl enable auto_startVPN.service // 设置开机启动刚刚新建的自动连接 vpn 的服务\n重启电脑，等待个大约 10 多秒，执行 ifconfig, 会发现连接中会有 ppp0 这个网卡设备和对应的 ip 地址等信息，说明脚本执行成功也成功的自动连接上了 vpn 服务器.\n","tags":["linux"]},{"title":"pdfbox 解析 PDF 文件","url":"/pdfbox%E8%A7%A3%E6%9E%90PDF%E6%96%87%E4%BB%B6/","content":"摘要:\n  最近需要使用到对PDF文件内容进行解析,然后对文件的部分内容进行索引查询.在解析的PDF的时候Java语言有2个\n  开源的PDF工具:PDFbox和Itext.\n\nPDFbox 和 Itext 都能读取、解析 pdf 文件，并且可对文件进行修改。有小伙伴将 2 个工具对比总结出以下结论:在读取和解析 PDF 的时候使用 PDFBox，较为简单，示例较为详细；修改 PDF 的时候使用 Itext，支持粒度较细，比如控制文字字体等\nItext  iText 是著名的开放项目，是用于生成 PDF 文档的一个 java 类库。通过 iText 不仅可以生成 PDF 或 rtf 的文档，而且可以将 XML、Html 文件转化为 PDF 文件等。目前只是用到对 PDF 文档的解析，所以对于 Itext 具体使用暂未查看，\n官网:https://itextpdf.com/\n插入文字可以自定义字体，使用字库文件(ttf)\n\nPDFBox引入 PDFBox 工具库 jar&lt;dependency&gt;\n    &lt;groupId&gt;org.apache.pdfbox&lt;/groupId&gt;\n    &lt;artifactId&gt;pdfbox&lt;/artifactId&gt;\n    &lt;version&gt;2.0.15&lt;/version&gt; &lt;!--当前使用2.0.15的版本--&gt;\n&lt;/dependency&gt;\n\n编写 PDFUtils 类import org.apache.pdfbox.cos.COSName;\nimport org.apache.pdfbox.io.RandomAccessBuffer;\nimport org.apache.pdfbox.pdfparser.PDFParser;\nimport org.apache.pdfbox.pdmodel.PDDocument;\nimport org.apache.pdfbox.pdmodel.PDPage;\nimport org.apache.pdfbox.pdmodel.graphics.image.PDImageXObject;\nimport org.apache.pdfbox.text.PDFTextStripper;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport java.io.File;\nimport java.io.FileInputStream;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.nio.file.Paths;\nimport java.util.ArrayList;\nimport java.util.List;\n\n/**\n * pdf文档解析工具类\n *\n * @author bz\n */\npublic class PDFUtils {\n\n    private static final Logger logger = LoggerFactory.getLogger(PDFUtils.class);\n\n    /**\n     * @param pdfPath pdf文件路径\n     * @return\n     */\n    public static PDDocument initPDDocument(String pdfPath) throws Exception {\n        File pdfFile = Paths.get(pdfPath).toFile();\n        if (!pdfFile.exists()) {\n            logger.error(\"pdf文件不存在\");\n            return null;\n        }\n        // 新建一个PDF解析器对象\n        PDFParser pdfParser = new PDFParser(new RandomAccessBuffer(new FileInputStream(pdfFile)));\n        // 对PDF文件进行解析\n        pdfParser.parse();\n        // 获取解析后得到的PDF文档对象\n        PDDocument pdfdocument = pdfParser.getPDDocument();\n        return pdfdocument;\n    }\n\n    /**\n     * @param inputStream 输入流\n     * @return\n     */\n    public static PDDocument initPDDocument(InputStream inputStream) throws Exception {\n        // 新建一个PDF解析器对象\n        PDFParser pdfParser = new PDFParser(new RandomAccessBuffer(inputStream));\n        // 对PDF文件进行解析\n        pdfParser.parse();\n        // 获取解析后得到的PDF文档对象\n        PDDocument pdfdocument = pdfParser.getPDDocument();\n        return pdfdocument;\n    }\n\n    /**\n     * 解析pdf文档中的字符内容\n     *\n     * @param pdDocument\n     * @param startPage  开始页码\n     * @param endPage    结束页码\n     * @return\n     */\n    public static String getContent(PDDocument pdDocument, int startPage, int endPage) throws IOException {\n        if (endPage &lt;= startPage) {\n            logger.error(\"页码参数不正确\");\n            return null;\n        }\n        // 新建一个PDF文本剥离器\n        PDFTextStripper stripper = new PDFTextStripper();\n        stripper.setStartPage(startPage); // 开始提取页数\n        stripper.setEndPage(endPage); // 结束提取页数\n        // 从PDF文档对象中剥离文本\n        String result = stripper.getText(pdDocument);\n        return result;\n    }\n\n    /**\n     * 解析pdf文档中的所有图片列表\n     *\n     * @param pdDocument\n     * @param startPage  开始页码\n     * @param endPage    结束页码\n     * @return\n     */\n    public static List&lt;PDImageXObject&gt; getImageList(PDDocument pdDocument, int startPage, int endPage) throws IOException {\n        if (endPage &lt;= startPage) {\n            logger.error(\"页码参数不正确\");\n            return null;\n        }\n        List&lt;PDImageXObject&gt; imageList = new ArrayList&lt;PDImageXObject&gt;();\n        for (int i = startPage; i &lt; endPage; i++) {\n            PDPage page = pdDocument.getPage(i);\n            Iterable&lt;COSName&gt; objectNames = page.getResources().getXObjectNames();\n            for (COSName imageObjectName : objectNames) {\n                if (page.getResources().isImageXObject(imageObjectName)) {\n                    PDImageXObject imageXObject = (PDImageXObject) page.getResources()\n                            .getXObject(imageObjectName);\n                    imageList.add(imageXObject);\n                }\n            }\n        }\n        return imageList;\n    }\n\n}\n\n调用 PDFUtils 类方法@Test\npublic void test4() throws Exception {\n    PDDocument pdDocument = PDFUtils.initPDDocument(\"/home/bz/Desktop/1.pdf\");\n    if (pdDocument != null) {\n        // 获取文档文本内容\n        String result = PDFUtils.getContent(pdDocument, 0, pdDocument.getNumberOfPages());\n        System.out.println(\"PDF文件的文本内容如下：\");\n        System.out.println(result);\n        // 获取文档中的所有图片\n        List&lt;PDImageXObject&gt; imageList = PDFUtils.getImageList(pdDocument, 0,pdDocument.getNumberOfPages());\n        for (int i = 0; i &lt; imageList.size(); i++) {\n            PDImageXObject imageXObject = imageList.get(i);\n            BufferedImage bufferedImage = imageXObject.getImage();\n            ImageIO.write(bufferedImage, imageXObject.getSuffix(),\n                    new FileOutputStream(Paths\n                            .get(\"/home/bz/Desktop/\" + i + \".\" + imageXObject.getSuffix()).toFile()));\n        }\n    }\n}\n","tags":["java","pdfbox","pdf"]},{"title":"linux 系统之间远程连接和传输文件","url":"/linux%E7%B3%BB%E7%BB%9F%E4%B9%8B%E9%97%B4%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5%E5%92%8C%E4%BC%A0%E8%BE%93%E6%96%87%E4%BB%B6/","content":"&gt;摘要: \n        \n1.Windows与Windows系统之间可以开启远程桌面连接实现远程控制和传输文件,也可以搭建ftp服务器然后通过ftp客户端\n(例如:fileZilla)来实现.\n2.从Windows到Linux,可以使用xshell等工具来实现远程连接.然后使用winscp等工具实现文件传输.当然在Linux上\n搭建ftp服务器,然后用ftp客户端连接也可\n3.从Linux(桌面版,server版一般没必要)到Windows.可以使用remmina工具来远程连接Windows进行连接操作.\n文件拷贝推荐在Windows上搭建ftpserver(fileZilla-server),然后使用fileZilla client连接传输文件.\n\n 注:fileZilla跨平台的.占用资源少,操作方便.简直神器~\n \n4.另外一种方式就是不分双方的操作系统.只要在对应的机器上安装对应的一些工具,比如teamviewer等.也可实现远程连接\n和文件传输.\n5.Linux到Linux之间通常是桌面端到server端的操作,有时候为了方便或者为了减少服务器资源占用,server端不需要安装\n额外的一些工具等,这时推荐使用Linux下的ssh和scp命令进行操作(大力推荐~)\n\n1.ssh 命令  简单说，SSH 是一种网络协议，用于计算机之间的加密登录。如果一个用户从本地计算机，使用 SSH 协议登录另一台远程计算机，我们就可以认为，这种登录是安全的，即使被中途截获，密码也不会泄露.SSH 只是一种协议，存在多种实现，既有商业实现，也有开源实现。本文针对的实现是 OpenSSH (linux 一般自带)，它是自由软件，应用非常广泛。注:ssh 协议默认端口一般是 22\nssh -V 查看当前安装的ssh版本\n\n1.1 连接到远程主机方式 1\nssh username@serverAddress username是登录远程主机的用户名,serverAddress远程主机地址\n\n1.2 连接到远程主机方式 2\nssh serverAddress -l username -p 22 serverAddress远程主机地址,可以是一个域名地址或者ip地址,\nusername是登录远程主机的用户名, -p 指定远程服务端ssh协议开放的端口.\n\n2.scp 命令scp用于实现在Linux server端和Linux客户端实现文件传输\n\n2.1 上传文件到服务器端，注：是文件，不是文件夹\nscp ./test.js root@192.168.1.106:/var/www/ #将本地当前目录下的test.js文件上传到192.168.1.106的\n/var/www/目录下.root登录远程及其的用户名.\n\n2.2 上传文件夹 (目录) 到服务器端\nscp -r ./test/ root@192.168.1.106:/var/www/ #将本地当前目录下的test目录上传到192.168.1.106的/var/www/目录下.\n-r参数代表上传目录\n\n2.3 从服务器上下载文件\nscp root@192.168.1.106:/var/www/test.js /home/ #将服务器/var/www/目录下的test.js文件下载到本地的home目录下\n\n2.4 从服务器下载整个目录\nscp -r root@192.168.1.106:/var/www/test/ /home/ #将服务器上的/var/www/test/目录下载到本地的home目录下\n-r参数代表目录\n\n","tags":["linux"]},{"title":"nginx 限制某个 IP 同一时间段的访问次数","url":"/nginx%E9%99%90%E5%88%B6%E6%9F%90%E4%B8%AAIP%E5%90%8C%E4%B8%80%E6%97%B6%E9%97%B4%E6%AE%B5%E7%9A%84%E8%AE%BF%E9%97%AE%E6%AC%A1%E6%95%B0/","content":"  摘要:\nnginx可以通过HttpLimitReqModul和HttpLimitZoneModule配置来限制ip在同一时间段的访问次数来防cc攻击\n\nHttpLimitReqModul用来限制连单位时间内连接数的模块，使用limit_req_zone和limit_req指令配合使用来达到限制。一旦并发连接超过指定数量，就会返回503错误。\n\nHttpLimitConnModul用来限制单个ip的并发连接数，使用limit_zone和limit_conn指令\n\n注:两个模块的区别前一个是对一段时间内的连接数限制，后者是对同一时刻的连接数限制\n\nHttpLimitReqModul 限制某一段时间内同一 ip 访问数实例在 http 作用域下配置 limit_req_zone 指令，如下:      http{\n      ...\n      #定义一个名为allips的limit_req_zone用来存储session，大小是10M内存，\n      #以$binary_remote_addr 为key,限制平均每秒的请求为20个，\n      #1M能存储16000个状态，rete的值必须为整数，\n      #如果限制两秒钟一个请求，可以设置成30r/m\n      limit_req_zone $binary_remote_addr zone=allips:10m rate=20r/s;\n      ...\n      server{\n          ...\n          location {\n              ...\n  \n              #限制每ip每秒不超过20个请求，漏桶数burst为5\n              #brust的意思就是，如果第1秒、2,3,4秒请求为19个，\n              #第5秒的请求为25个是被允许的。\n              #但是如果你第1秒就25个请求，第2秒超过20的请求返回503错误。\n              #nodelay，如果不设置该选项，严格使用平均速率限制请求数，\n              #第1秒25个请求时，5个请求放到第2秒执行，\n              #设置nodelay，25个请求将在第1秒执行。\n  \n              limit_req zone=allips burst=5 nodelay;\n              ...\n          }\n          ...\n      }\n      ...\n}\nHttpLimitZoneModule 限制并发连接数实例在 http 作用域下配置 limit_zone 指令，limit_zone 只能定义在 http 作用域，limit_conn 可以定义在 http server location 作用域。如下\n  http{\n    ...\n \n    #定义一个名为one的limit_zone,大小10M内存来存储session，\n    #以$binary_remote_addr 为key\n    #nginx 1.18以后用limit_conn_zone替换了limit_conn\n    #且只能放在http作用域\n    limit_conn_zone   one  $binary_remote_addr  10m; \n    ...\n    server{\n        ...\n        location {\n            ...\n           limit_conn one 20;          #连接数限制\n \n           #带宽限制,对单个连接限数，如果一个ip两个连接，就是500x2k\n           limit_rate 500k;           \n \n            ...\n        }\n        ...\n    }\n    ...\n}\n\nnginx 白名单设置上面默认配置对多有的 ip 都有限制，有些时候我们不希望对搜索引擎的蜘蛛或者自己测试 ip 进行限制，对于特定的白名单 ip 我们可以借助 geo 指令实现，如下:\ngeo指令定义了一个白名单$limited变量，默认值为1，如果客户端ip在上面的范围内，$limited的值为0\n\nhttp{\n   geo $limited{\n      default 1;\n      #google\n      64.233.160.0/19 0;\n      65.52.0.0/14 0;\n      66.102.0.0/20 0;\n      66.249.64.0/19 0;\n      72.14.192.0/18 0;\n      74.125.0.0/16 0;\n      209.85.128.0/17 0;\n      216.239.32.0/19 0;\n      #M$\n      64.4.0.0/18 0;\n      157.60.0.0/16 0;\n      157.54.0.0/15 0;\n      157.56.0.0/14 0;\n      207.46.0.0/16 0;\n      207.68.192.0/20 0;\n      207.68.128.0/18 0;\n      #yahoo\n      8.12.144.0/24 0;\n      66.196.64.0/18 0;\n      66.228.160.0/19 0;\n      67.195.0.0/16 0;\n      74.6.0.0/16 0;\n      68.142.192.0/18 0;\n      72.30.0.0/16 0;\n      209.191.64.0/18 0;\n      #My IPs\n      127.0.0.1/32 0;\n      123.456.0.0/28 0; #example for your server CIDR\n  }","tags":["nginx"]},{"title":"nginx-rtmp-module-ffmpeg 视频推流和 rtsp 转 rtmp 及 hls","url":"/nginx-rtmp-module-ffmpeg%E8%A7%86%E9%A2%91%E6%8E%A8%E6%B5%81%E5%92%8Crtsp%E8%BD%ACrtmp%E5%8F%8Ahls/","content":"RTSP、RTMP、HTTP 协议比较共同点1. 都是用在应用层的协议\n2. 理论上这三种协议都可以做直播和点播，但直播一般用 RTSP 和 RTMP 点播用 HTTP\n不同点1.HTTP 协议（HyperText Transfer Protocol，超文本传输协议)，是因特网上应用最为广泛的一种网络传输协议，所有的 WWW 文件都必须遵守这个标准，HTTP 是一个基于 TCP/IP 通信协议来传递数据 (HTML 文件，图片文件，查询结果等). 所以 HTTP 不是流媒体协议，RTMP 和 RTSP 是流媒体协议\n2.RTMP 是 Real Time Messaging Protocol（实时消息传输协议）的首字母缩写。该协议基于 TCP，是一个协议族，包括 RTMP 基本协议及 RTMPT/RTMPS/RTMPE 等多种变种。RTMP 是一种设计用来进行实时数据通信的网络协议，主要用来在 Flash/AIR 平台和支持 RTMP 协议的流媒体 / 交互服务器之间进行音视频和数据通信，RTMP 一般传输 flv,f4v 格式流.\n3.RTSP（Real Time Streaming Protocol），RFC2326，实时流传输协议.RTSP 以客户端方式工作，对流媒体提供播放、暂停、后退、前进等操作.RTSP 传输的一般是 TS、MP4 格式的流，其传输一般需要 2~3 个通道，命令和数据通道分离。使用 RTSP 协议传输流媒体数据需要有专门的媒体播放器和媒体服务器，也就是需要支持 RTSP 协议的客户端和服务器。\nffmpeg 简介FFmpeg 是一套可以用来记录、转换数字音频、视频，并能将其转化为流的开源计算机程序。它包括了目前领先的音 / 视频编码库 libavcodec. 可以轻易地实现多种视频格式之间的相互转换，例如可以将摄录下的视频 avi 等转成现在视频网站所采用的 flv 格式\nnginx+nginx-rtmp-moudle 安装分别下载 nginx 和 nginx-rtmp 的源码然后进行编译即可。在此，为了方便我是直接使用的 docker 的 tiangolo/nginx-rtmp 镜像，docker 安装参考上一篇初识 docker 文档\ndocker pull tiangolo/nginx-rtmp // 拉取 nginx-rtmp 镜像\ndocker run -it --name nginx-rtmp tiangolo/nginx-rtmp -p 1935:1935 // 第一次运行容器，取个别名，后续可直接使用 docker start nginx-rtmp\n使用 netstat -tunlp | grep 1935 检测 1935 端口是否正在监听，正常情况是正在监听中\nffmpeg 安装sudo apt install ffmpeg // 安装 ffmpeg (我当前环境 deepin, 仓库里面自带 ffmpeg 包)\n其他操作系统需要去官网下载对应的安装包即可或者按照官方文档添加对应系统的 ppa 进行安装即可.\nffmpeg 参数:\n-re : 表示使用文件的原始帧率进行读取，因为 ffmpeg 读取视频帧的速度很快，如果不使用这个参数，ffmpeg 可以在很短时间就把 video.mp4 中的视频帧全部读取完并进行推流，这样就无法体现出视频播放的效果了\n-i : 这个参数表示输入 ，后面跟的路劲文件就是输入文件。\n-vcodec copy : -vcodec 表示使用的视频编解码器 ，前缀 v 表示 video。后面紧跟的 copy 表示复制使用源文件的视频编解码器，比如原文件的编解码器 (codec) 是 h264，则这里就使用 h264\n-acodec copy : -acodec 表示使用的音频编解码器，前缀 a 表示 audio。后面的 copy 表示使用源文件的音频编解码器\n-b:v 800k : -b:v 表示视频的比特率 (bitrate) ，为 800k\n-b:a 32k : 表示音频的比特率为 32k\n-f flv : -f 表示 format ，就是强制输出格式为 flv，这一步其实也叫封装 (mux)，封装要做的事就是把视频和音频混合在一起，进行同步。紧跟在后面的 rtmp://xxx.xxx.xxx/xxx 表示输出的” 文件名”，这个文件名可以是一个本地的文件，也可以指定为 rtmp 流媒体地址。指定为 rtmp 流媒体地址后，则 ffmpeg 就可以进行推流\nffmpeg 将 rtsp 转码为 rtmp使用 ffmpeg 命令，将 rtsp 转码为 rtmp.ffmpeg 参数项很多，未对其深究，直接参考网友的命令的.-i 后面是 rtsp 流地址.\nffmpeg -re -rtsp_transport tcp -i \"rtsp://184.72.239.149/vod/mp4://BigBuckBunny_175k.mov\" -f flv -vcodec libx264 -vprofile baseline -acodec aac -ar 44100 -strict -2 -ac 1 -f flv -r 10 -s 1280x720 -q 10 \"rtmp://127.0.0.1:1935/live/demo\"\n在执行转码命令过程中,可能会报信息类似 Past duration 0.999992 too large 的警告错误,经查询资料,是在-r参数后面\n指定的视频帧率参数导致的.rtsp://184.72.239.149/vod/mp4://BigBuckBunny_175k.mov这个地址是网络上的地址,\n可使用vlc media player查看源的帧率而设置\n\n使用 VLC media player 测试播放转换后的 rtmp 地址打开 VLC media player 播放器。在工具栏” 媒体 -&gt; 打开网络串流” 然后输入 rtmp://127.0.0.1:1935/live/demo 点击确定即可进行直播预览转换后的 rtmp 视频流\n\nffmpeg 将 rtsp 转码为 hls使用 ffmpeg 命令，将 rtsp 转码为 hls.ffmpeg 参数项很多，未对其深究，直接参考网友的命令的.-i 后面是 rtsp 流地址.\nffmpeg -f rtsp -rtsp_transport tcp -i rtsp://192.168.100.2/longzhu/demo_2 -r 23 -f hls -hls_time 4 -hls_list_size 5 -hls_wrap 10 /home/bz/Desktop/h5live/longzhuchao.m3u8\n在执行转码命令过程中,可能会报信息类似 Past duration 0.999992 too large 的警告错误,经查询资料,是在-r参数后面\n指定的视频帧率参数导致的.rtsp://184.72.239.149/vod/mp4://BigBuckBunny_175k.mov这个地址是网络上的地址,\n可使用vlc media player查看源的帧率而设置\n\n使用 VLC media player 测试播放转换后的 hls 地址 (m3u8 文件)打开 VLC media player 播放器。在工具栏” 媒体 -&gt; 打开网络串流” 然后输入 http://192.168.100.31/hlsvideo/longzhuchao.m3u8 点击确定即可进行直播预览转换后的 rtmp 视频流，该地址是在 nginx 中配置了的\n\nffmpeg 推送视频文件到 rtsp 服务器ffmpeg -re -i ./龙珠超.布罗利.mp4 -vcodec copy -codec copy -f rtsp rtsp://192.168.252.1/longzhu/demo_2\n注:使用了easydarwin,rtsp://192.168.252.1地址就是启动easydarwin成功后的rtsp server地址\n\n使用 VLC media player 测试播放推流后 rtsp 地址\nffmpeg 推送视频文件到 rtmp 服务器ffmpeg -re -i ./龙珠超.布罗利.mp4 -vcodec copy -acodec copy -b:v 800k -b:a 32k -f flv rtmp://192.168.100.31:1935/rtmplive_demo/demo_3\n注:rtmp地址中的rtmplive_demo必须和nginx中配置的application名称一致才能推流成功,192.168.100.31是我的一台虚拟机\n\n使用 VLC media player 测试播放推流后 rtmp 地址\nffmpeg 转发 rtsp 流ffmpeg -i rtsp://192.168.100.2:8554/longzhu/live -codec copy -f rtsp rtsp://192.168.252.1/longzhu/demo_1\n第一个rtsp是源地址,第二个是新地址.但是必须保证新地址是能够支持rtsp协议的才行.我试过使用nginx+rtsp是不能够\n成功的.所以换成了easydarwin,rtsp://192.168.252.1地址就是启动easydarwin成功后的rtsp server地址.\n\n效果图如下:\n\n注：关于测试 rtsp 地址问题，上面的地址我测试的时候能够使用，但是不能保证以后能够一直正常使用，所以有网友图文讲解了使用 VLC media player 自制 rtsp 流。小伙伴的力量强大！其地址如下:https://blog.csdn.net/taoerit/article/details/51920018为了防止地址失效，我将页面截了一张完整图。图片如下:\n\n","tags":["nginx","rtmp","rtsp","ffmpeg"]},{"title":"tomcat 解决 java.lang.IllegalArgumentException: Invalid character 异常","url":"/tomcat%E8%A7%A3%E5%86%B3java-lang-IllegalArgumentException-Invalid-character%E5%BC%82%E5%B8%B8/","content":"\ntomcat 新版添加了对于 http 头的验证。出现 java.lang.IllegalArgumentException: Invalid character found in the request target. The valid char… 异常\n\n网上查找了几种方法归类\n1. 更换 tomcat 版本，但是 7,8,9 的版本都更换过，问题依然。但是有网友确实可以解决，但是更换到具体什么版本未知.\n2. 前端 http 请求的时候对参数进行 URL 编码处理，理论上是绝对可行的，但是已有的 http 请求数很多，一个一个修改工作量大。未试\n3. 配置 tomcat 的 catalina.properties 添加或者修改： tomcat.util.http.parser.HttpParser.requestTargetAllow=|{}\n4. 使用 Connector 中 relaxedPathChars 和 relaxedQueryChars 属性可以解决问题。找到 tomcat/conf/server.xml, 在 Connector 中增加这两个配置.&lt;Connector port=\"8080\" protocol=\"HTTP/1.1\"    relaxedPathChars=\"[]{}|\\^\" relaxedQueryChars=\"[]{}|\\^\" /&gt;\n","tags":["tomcat"]},{"title":"vscode 配置前端 vue 开发环境","url":"/vscode%E9%85%8D%E7%BD%AE%E5%89%8D%E7%AB%AFvue%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/","content":"摘要:\n  使用vscode配置前端vue开发环境\n\n1. 安装好 vscode 后，安装常用的几个插件\nAuto Close Tag : 自动闭合标签插件\n\nBeautify : 格式化js,json,css,sass,html等文件\n\nESLint : 使用eslint规范对代码进行处理\n\nfile-icons : 文件图标,便利区分不同类型的文件\n\nMonokai Theme : 一款类似sublime text主流的主题设置,使界面美观,享受美好的编码心情\n\nPath Intellisense : 自动提示文件路径插件\n\nPrettier : 因为vscode默认的格式化是不能通过eslint校验规范的,需要改为此插件\n\nVetur : vscode的vue工具插件\n\nHTML CSS Support : 在标签中class属性的时候,提示class的名称\n\npx2rem : 将像素值转为rem插件\n\n下面是markdown相关的插件\n\nMarkdown-TOC : 对markdown文档生成目录的插件,有2个,请选择作者为AlanWalk的\n\n2. 安装好上述插件后，对其进行配置设置 (2018-12-15 更 v.1.30.0)\n在文件-&gt;首选项-&gt;设置-&gt;用户设置里面写入以下配置\n\n    {\n    \"workbench.startupEditor\": \"newUntitledFile\",\n    \"window.title\": \"${dirty}${activeEditorLong}${separator}${rootName}${separator}${appName}\",\n    \"extensions.ignoreRecommendations\": false,\n    \"workbench.iconTheme\": \"file-icons\",\n    \"workbench.colorTheme\": \"Monokai\",\n    \"vetur.format.defaultFormatter.js\": \"vscode-typescript\",\n    \"extensions.autoUpdate\": false,\n    \"update.channel\": \"none\",\n    \"eslint.autoFixOnSave\": false,\n    \"files.autoSave\": \"off\",\n    \"eslint.validate\": [\n        \"javascript\",\n        \"javascriptreact\",\n        {\n            \"language\": \"vue\",\n            \"autoFix\": true\n        },\n        {\n            \"language\": \"html\",\n            \"autoFix\": true\n        },\n        \"vue\"\n    ],\n    \"eslint.options\": {\n        \"plugins\": [\n            \"html\"\n        ]\n    },\n    \"editor.tabSize\": 2,\n    \"prettier.eslintIntegration\": true,\n    \"vetur.format.defaultFormatterOptions\": {\n        \"html\": \"prettier\",\n        \"css\": \"prettier\",\n        \"postcss\": \"prettier\",\n        \"scss\": \"prettier\",\n        \"less\": \"prettier\",\n        \"js\": \"prettier\",\n        \"ts\": \"prettier\",\n        \"stylus\": \"stylus-supremacy\",\n        \"wrap_attributes\": \"force-aligned\",\n        \"prettier\": {\n            \"semi\": false,\n            \"singleQuote\": true\n        }\n    },\n    \"eslint.alwaysShowStatus\": true,\n    \"window.titleBarStyle\": \"custom\",\n    \"files.eol\": \"\\n\"\n}\n3.vscode 1.29 版本以上 markdown-toc 生成目录默认是有问题的，1.29 版本以下能够直接正常使用\n    1.29版本以上,请在file-&gt;preferences-&gt;setting-&gt;text editor中找到Eol配置的地方,设置为\\n即可.\n    详细情况见 https://github.com/AlanWalk/markdown-toc/issues/65\n\n4.vscode 1.30 版本在 file-&gt;preferences-&gt;setting 下找不到打开 setting.json 文件的入口了。如下图，可以在系统路径下找到该文件编辑即可.\n    文件路径\n    Windows: %APPDATA%\\Code\\User\\settings.json\n    macOS: $HOME/Library/Application Support/Code/User/settings.json\n    Linux: $HOME/.config/Code/User/settings.json\n\n\n","tags":["vscode"]},{"title":"使用 hexo+Next 創建和部署個人博客","url":"/%E4%BD%BF%E7%94%A8hexo%E5%89%B5%E5%BB%BA%E5%92%8C%E9%83%A8%E7%BD%B2%E5%80%8B%E4%BA%BA%E5%8D%9A%E5%AE%A2/","content":"安裝 NodeJs 和 Git下载\nNode.js\nGit\n\n根據安裝界面自行安裝\n安裝 hexoHexo 官网\n打开终端（或命令行窗口），运行以下命令来安装 Hexo (-g 為全局安裝)\nnpm install hexo-cli -g\n\nhexo 新建項目，或從 github 下載博客源碼在你选择存储博客文件的目录中，执行以下命令来创建一个新的 Hexo 项目：\nhexo init blog\ncd blog\nnpm install\n\n配置 hexo编辑根目錄下的 _config.yml 文件，配置你的基本信息和其他相关设置\n具體參考：https://hexo.io/docs/configuration\n例如：\n# Site\ntitle: ArHay\nsubtitle: 当赤道留住雪花，眼泪融掉细沙\ndescription: \nkeywords: ArHay\nauthor: ArHay\nlanguage: zh-CN\ntimezone: ''\n\n創建文章使用以下命令创建新的博客文章\nhexo new post \"My New Post\"\n\n生成靜態文件在博客根目录下执行以下命令生成静态文件，文件存儲在 public 文件夾下：\nhexo generate\n\n或\nhexo g\n\n本地預覽hexo server\n\n或\nhexo s\n\n部署到 GithubPage安装 hexo-deployer-gitnpm install hexo-deployer-git --save\n\n参数 –save 的作用是在项目下的 package.json 文件记录安装过的依赖包名称。\n当复制项目到另外的电脑上，只需运行命令: npm i 就能自动安装项目用到的依赖包。\n编辑 _config.yml 文件配置你的博客信息、GitHub Pages 信息和其他相关设置\n# Deployment\n## Docs: https://hexo.io/docs/one-command-deployment\ndeploy:\n  type: git\n  repository: https://github.com/ArHay0612/arhay0612.github.io.git\n  branch: master\n\n部署运行以下命令将生成的静态文件部署到 GitHub Pages\nhexo deploy\n\n或\nhexo d\n\n然後根據彈窗完成登錄，即可部署完成\n訪問博客https://ArHay0612.github.io\nArHay0612 是我的用戶名。請自行替換到自己的 github usernames\n主題配置我用的是 Next，就以 Next 為例\n參考:\n\nNext Github Page\n\nNexT Documentation\n\n\n安裝 Next 主題在博客項目根目錄下把 Next 主題 clone 到 themes/next 文件夾\ncd hexo-site\ngit clone https://github.com/next-theme/hexo-theme-next themes/next\n\n編輯 _config.yml 文件在根目錄下找到 _config.yml\n然後在 theme 配置項修改成\ntheme: next\n\nNext 主題選擇next 自帶 4 種類型的主題方案\n\nMuse\nMist\nPisces\nGemini\n\n在 themes\\next\\_config.yml 文件下搜索 Scheme Settings\n然後選擇自己喜歡的主題方案\n# Schemes\n# scheme: Muse\n# scheme: Mist\nscheme: Pisces\n# scheme: Gemini\n\n# Dark Mode\ndarkmode: true\n\nNext 主題配置Next 主題所有配置都在 themes\\next\\_config.yml 文件下\n根據需求選擇自己需要的內容，如菜單，統計，搜索，背景等……\n具體參考：\n\nNext 主題設置 documentation\n\n例如：\nmenu:\n  home: / || fa fa-home #主頁\n  about: /about/ || fa fa-user #關於頁\n  tags: /tags/ || fa fa-tags  #標籤\n  #categories: /categories/ || fa fa-th\n  archives: /archives/ || fa fa-archive #歸檔\n  #schedule: /schedule/ || fa fa-calendar\n  #sitemap: /sitemap.xml || fa fa-sitemap\n  #commonweal: /404/ || fa fa-heartbeat\n\n插件選擇本地搜索該功能允許用戶在網站內快速搜索文章內容，而不依賴於外部搜索服務（如 Algolia）。本地搜索的數據由 Hexo 生成，並存儲在靜態文件中，適合小型或中型博客。\n參考：https://github.com/next-theme/hexo-generator-searchdb\n安裝npm install hexo-generator-searchdb --save\n\n配置插件在 Next 的配置文件 themes\\next\\_config.yml 中修改成以下內容：\n# Local Search\n# Dependencies: https://github.com/next-theme/hexo-generator-searchdb\nlocal_search:\n  enable: true #控制是否啟用本地搜索功能\n  # 設置每篇文章中顯示的搜索結果數量。 -1 顯示所有。\n  top_n_per_article: 1\n  # 控制是否將 HTML 字符（如 &amp;lt; 和 &amp;gt;）轉換為可讀的文本。\n  unescape: false\n  # 控制是否在頁面加載時預加載搜索數據\n  preload: true\n\nHexo PanguHexo Pangu 是一個用於自動處理中英文之間空格的插件，基於 Pangu.js。它的作用是自動在中文與英文、數字、符號之間插入適當的空格，從而提升文章的可讀性，符合中文排版的最佳實踐。\n參考：\n\nhttps://github.com/next-theme/hexo-pangu\nhttps://github.com/vinta/pangu.js\n\n安裝npm install hexo-pangu --save\n\nHexo Word CounterHexo Word Counter 是一個用於統計文章字數和預估閱讀時間的插件。它的主要作用是為每篇文章顯示字數和閱讀時間，幫助讀者了解文章的長度和閱讀所需的時間，從而提升用戶體驗。\n參考：https://github.com/next-theme/hexo-word-counter\n安裝npm install hexo-word-counter --save\n\n配置插件在 Next 的配置文件 themes\\next\\_config.yml 中修改成以下內容：\nsymbols_count_time:\n  separated_meta: true\n  item_text_total: false\n\noh-my-live2d是一個用於在 Hexo 博客中添加 Live2D 模型 的插件。它的作用是為網站添加一個可交互的 2D 虛擬角色，通常顯示在網站的角落，增強網站的趣味性和吸引力。（看板娘）\n參考：https://github.com/next-theme/hexo-word-counter\n安裝npm install hexo-oh-my-live2d --save\n\n配置插件在博客根目錄的配置文件 .\\_config.yml 中修改成以下內容：\nOhMyLive2d:\n  enable: true\n  CDN: https://registry.npmmirror.com/oh-my-live2d/latest/files\n  option:\n    dockedPosition: 'right' # 模型停靠位置 默认值: 'right' 可选值: 'left' | 'right'\n    menus: # 侧边栏菜单配置\n      items:  # 菜单项配置\n        - id: 'github'\n          icon: 'icon-switch'\n          title: '我的github'\n          onClick: ()=&gt;window.open('https://github.com/ArHay0612')\n\n    mobileDisplay: true # 是否在移动端显示\n    models:\n      - path: \\live2d_models\\fll\\fll.model3.json # 模型的路径\n        mobilePosition: [-10, 23] # 移动端时模型在舞台中的位置。 默认值: [0,0] [横坐标, 纵坐标]\n        mobileScale: 0.1 # 移动端时模型的缩放比例 默认值: 0.1\n        mobileStageStyle: # 移动端时舞台的样式\n          width: 180\n          height: 166\n        motionPreloadStrategy: IDLE # 动作预加载策略 默认值: IDLE 可选值: ALL | IDLE | NONE\n        position: [-10, 35] # 模型在舞台中的位置。 默认值: [0,0] [横坐标, 纵坐标]\n        scale: 0.15 # 模型的缩放比例 默认值: 0.1\n        # showHitAreaFrames: false # 是否显示点击区域 默认值: false\n        stageStyle:\n          width: 300\n          height: 450\n    parentElement: document.body #为组件提供一个父元素，如果未指定则默认挂载到 body 中\n    primaryColor: 'var(--btn-bg)' # 主题色 支持变量\n    sayHello: false # 是否在初始化阶段打印项目信息\n    tips:\n      style:\n        width: 230\n        height: 120\n        left: calc(50% - 20px)\n        top: -100px\n      mobileStyle:\n        width: 180\n        height: 80\n        left: calc(50% - 30px)\n        top: -100px\n      idleTips:\n        interval: 10000\n        duration: 1500\n        message:\n          - 你好呀,欢迎来到ArHay的小站~\n\n更換模型在互聯網上下載自己喜歡的 live2D 模型參考：\n\nLive2D 官方示例数据集（可免费下载\n\n模之屋\n\nGitHub 用戶 Eikanya 分享\n\n\n項目引入模型在 source 文件夾下，新建文件夾 live2d_models\\\n把下載下來的整個 live2d 資源包整個放進 live2d_models\\ 文件夾中\n然後修改 Hexo 的主配置文件 _config.yml\nmodels:\n      - path: \\live2d_models\\fll\\fll.model3.json # 模型的路径\n\n此處路徑應為這個模型包下的 json 文件\n預覽\n博客訪客和閱讀量統計busuanzi（不蒜子） 是一個輕量級的網站訪問量和文章閱讀量統計工具，適合用於 Hexo 博客等靜態網站。它無需註冊或配置後端服務，通過嵌入 JavaScript 即可實現訪問量和閱讀量的統計。\n參考：https://busuanzi.ibruce.info/\n配置插件在 Next 的配置文件 themes\\next\\_config.yml 中修改成以下內容：\n# Show Views / Visitors of the website / page with busuanzi.\n# For more information: http://ibruce.info/2015/04/04/busuanzi/\nbusuanzi_count:\n  enable: true\n  total_visitors: true\n  total_visitors_icon: fa fa-user\n  total_views: true\n  total_views_icon: fa fa-eye\n  post_views: true\n  post_views_icon: far fa-eye\n\n\n\n等我發掘到好玩的插件會繼續更新～\n未完待續……\n\n","tags":["nodejs","hexo"]},{"title":"基于 vue 组件实现 web 端页面调用摄像头拍照","url":"/%E5%9F%BA%E4%BA%8Evue%E7%BB%84%E4%BB%B6%E5%AE%9E%E7%8E%B0web%E7%AB%AF%E9%A1%B5%E9%9D%A2%E8%B0%83%E7%94%A8%E6%91%84%E5%83%8F%E5%A4%B4%E6%8B%8D%E7%85%A7/","content":"摘要:\n  基于vue组件化方式实现PC web端页面调用摄像头拍照功能,测试是在chrome浏览器的环境下.\n\n1. 封装 TakePhoto 组件，组件里面暴露出始化摄像头，拍照并且返回拍照后图片的 base64 码的方法\nTakePhoto 组件的全部代码如下:\n&lt;template&gt;\n  &lt;div class=\"wrapper\"&gt;\n    &lt;video\n      ref=\"video\"\n      :width=\"width\"\n      :height=\"height\"\n      autoplay\n      style=\"width= 100%; height=100%; object-fit: fill\"\n    &gt;&lt;/video&gt;\n    &lt;canvas ref=\"canvas\" width=\"300\" height=\"400\" v-show=\"taked\"&gt;&lt;/canvas&gt;\n  &lt;/div&gt;\n&lt;/template&gt;\n&lt;script&gt;\nexport default {\n  name: 'TakePhoto',\n  props: {\n    width: {\n      default: 300 // 不传默认300\n    },\n    height: {\n      default: 400 // 不传默认400\n    }\n  },\n  data() {\n    return {\n      video: null,\n      track: '',\n      taked: false\n    }\n  },\n  methods: {\n    init(call) {\n      this.taked = false\n      this.video = this.$refs.video\n      navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia\n      if (navigator.getUserMedia) {\n        navigator.getUserMedia({ video: true },\n          (stream) =&gt; {\n            this.track = stream.getTracks()[0]  // 通过这个关闭摄像头\n            try {\n              this.video.src = window.URL.createObjectURL(stream) // chrome版本&lt;=70\n            } catch (e) {\n              this.video.srcObject = stream // chrome版本&gt;70\n            }\n            this.video.onloadedmetadata = (e) =&gt; {\n              console.log(e)\n              this.video.play()\n              call(true)\n            }\n          }, (err) =&gt; {\n            console.log(err)\n            call(false)\n          }\n        )\n      } else {\n        call(false)\n      }\n    },\n    takePhoto(call) {\n      let canvas = this.$refs.canvas\n      let context2D = canvas.getContext('2d')\n      context2D.fillStyle = '#ffffff'\n      context2D.fillRect(0, 0, this.width, this.height)\n      context2D.drawImage(this.video, 0, 0, this.width, this.height)\n      let image_code = canvas.toDataURL('image/png')//图片的base64\n      this.taked = true\n      call(true, image_code)\n      if (null != this.track) {\n        this.track.stop()//关闭摄像头\n      }\n    }\n  },\n  destroyed() {\n    if (null != this.track) {\n      this.track.stop()//关闭摄像头\n    }\n  }\n}\n&lt;/script&gt;\n&lt;style scoped&gt;\ncanvas {\nposition: absolute;\nleft: 0;\ntop: 0;\nz-index: 1000;\n}\n.wrapper {\nposition: relative;\n}\n&lt;/style&gt;\n\n说明: 摄像区域的宽高由外部传入,不传采用默认的值.init()初始化摄像头,takePhoto()进行拍照操作\n\n2. 调用 TakePhoto 组件里面的方法进行拍照\n调用 TakePhoto 组件的关键代码如下:\n&lt;div&gt;\n  &lt;TakePhoto class=\"photo\" ref=\"photo\"&gt;&lt;/TakePhoto&gt;\n  &lt;div class=\"takePhoto-btn\" @click=\"handleTakePhoto\" {{statusMsg}}&lt;/div&gt;\n&lt;/div&gt;\n\nhandleTakePhoto() {\n  if (this.status === 1) { // 初始化摄像头\n    this.statusMsg = '查找设备中...'\n    this.$refs.photo.init((res) =&gt; {\n      if (res) {\n        this.status = 2\n        this.statusMsg = '拍照'\n      } else {\n        alert('未发现设备')\n      }\n    }) // 初始化摄像头\n  } else if (this.status === 2) { // 拍照\n    this.$refs.photo.takePhoto((res, img) =&gt; {\n      if (res) {\n        this.status = 3\n        console.log(img)\n        this.statusMsg = '重新拍'\n      }\n    })\n  } else if (this.status === 3) { // 重新拍\n    this.$refs.photo.init((res) =&gt; {\n      if (res) {\n        this.status = 2\n        this.statusMsg = '拍照'\n      } else {\n        alert('未发现设备')\n      }\n    }) // 初始化摄像头\n  }\n}\n\n说明:组件中定义statusMsg和status两个变量,statusMsg主要是改变整个流程中状态信息的提示,status是对应的状态码.\n\n3. 实际效果图\n\n","tags":["vue","web"]},{"title":"如何在 vscode 自動生成 md 目錄並轉換格式","url":"/%E5%A6%82%E4%BD%95%E5%9C%A8vscode%E8%87%AA%E5%8B%95%E7%94%9F%E6%88%90md%E7%9B%AE%E9%8C%84%E4%B8%A6%E8%BD%89%E6%8F%9B%E6%A0%BC%E5%BC%8F/","content":"vscode 自動生成 md 目錄並轉換格式\n前言\n工具準備\nvscode\nmarkdownlint\nMarkdown Preview Enhanced\nMarkdown All in One\nPrettier\n\n\n生成目錄\n轉換 md 格式\n\n前言之前在寫 API 文檔時，由於文件過長，跳轉十分麻煩，後面才想起來可以利用目錄跳轉就查找對應的 Markdown 目錄生成工具\n工具準備\nvscode\nmarkdownlint （vscode 插件）\nMarkdown Preview Enhanced （vscode 插件）\nMarkdown All in One （vscode 插件）\nPrettier （vscode 插件）\n\n\nvscode用於編寫 markdown 文件並預覽的 IDE\nmarkdownlint用於檢查 md 文件的編寫規範\nMarkdown Preview Enhanced用於預覽 md 文件和轉換成其他格式，如 PDF，HTML\nMarkdown All in One內置多種指令便於生成各種 md 格式\nPrettier用於 format md 文件（其實 markdownlint 或者 Markdown All in One 都可以，但是我對比發現這個更好用）\n生成目錄\nvscode 打開 md 文件\n\n將光標放在需要生成目錄的位置\n\n然後按下 ctrl+shift+P 輸入 Markdown Preview Enhanced: Create TOC\n\n使用關鍵字即可，如 mpetoc\n\n\n 會在光標位置自動生成以下語句  \n&lt;!-- @import \"[TOC]\" {cmd=\"toc\" depthFrom=1 depthTo=6 orderedList=false} --&gt;\n\n修改相關屬性\n\ndepthFrom ：從第幾級目錄開始生成\n depthTo ： 到第幾級目錄結束\n orderedList : 是否使用有序列表\n\n\n保存，會根據屬性自動生成目錄\n\n\n轉換 md 格式\nmd 文件編寫好後，右上角按鈕可以點開預覽\n\n在預覽界面點擊右鍵，會有導出選項  右鍵菜單還有其他選項，比如更換 preview 主題等，請自行摸索，本文不再贅述。\n\n根據所需的類型格式導出即可\n\n\n此方法僅支持轉換格式後的正常跳轉！如果是通過 hexo 發布的 md 網頁請使用 Markdown All in One: Create Table of Contents, 否則發布後不能跳轉！！！\n","tags":["pdf","vscode","markdown","html"]},{"title":"编译安装 nginx 添加 rtmp 模块","url":"/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85nginx%E6%B7%BB%E5%8A%A0rtmp%E6%A8%A1%E5%9D%97/","content":"摘要:nginx源码编译添加rtmp模块实现视频推流服务器\n环境:deepin linux 15.10.1(基于debian9)\n\n安装依赖库执行命令前，最好执行一次 sudo apt update 更新下仓库\nsudo apt install autoconf automake\nsudo apt install libpcre3 libpcre3-dev\nsudo apt install openssl\nsudo apt install libssl-dev\n下载 nginx 和 nginx-rtmp-module 源码进入到一个目录 (可以自己新建), 然后 clone nginx 和 rtmp 模块的源码，地址可在 github 上面查找对应的仓库，然后进行 clone 操作 (需要安装 git)\ngit clone https://github.com/nginx/nginx.git --depth=1 //clone nginx 源码，指定克隆深度 depth 为 1 即表示只克隆最近一次 commit (clone 时间大幅缩短)\ngit clone https://github.com/arut/nginx-rtmp-module.git --depth=1 //clone nginx-rtmp-module 源码\n进入到 nginx 源码目录，有一个 auto 文件夹，里面有一个名为 configure 的文件。通过命令参数调用该文件，生成 MakeFile\ncd nginx // 进入到 nginx 源码目录\n./auto/configure --prefix=/opt/nginx --with-http_ssl_module --with-http_v2_module --with-http_flv_module --with-http_mp4_module --add-module=../nginx-rtmp-module/\nls -al // 查看当前目录 (nginx) 下的文件，会有一个产生的 MakeFile 文件\n编译和安装当前目录还是位于上一步的 nginx 目录\nmake // 编译\nsudo make install // 安装\n查看结果ls -l /opt/nginx/ // 查看 opt 目录下 nginx 目录的内容\nsudo /opt/nginx/sbin/nginx // 启动 nginx 服务，默认只能用 root 启动，所以加 sudo\nsudo chmod u+s /opt/nginx/sbin/nginx // 为 nginx 文件加上 setuid 标志.(setuid 只对文件有效). 设置后可以通过普通用户就可以启动\n\n关于 chmod 扩展：如果是一个可执行文件，那么在执行时，一般该文件只拥有调用该文件的用户具有的权限。而 setuid, setgid 可以来改变这种设置:\nsetuid: 设置使文件在执行阶段具有文件所有者的权限\nsetgid: 该权限只对目录有效。目录被设置该位后，任何用户在此目录下创建的文件都具有和该目录所属的组相同的组.\nsticky bit: 该位可以理解为防删除位。一个文件是否可以被某用户删除，主要取决于该文件所属的组是否对该用户具有写权限。如果没有写权限，则这个目录下的所有文件都不能被删除，同时也不能添加新的文件。如果希望用户能够添加文件但同时不能删除文件，则可以对文件使用 sticky bit 位。设置该位后，就算用户对目录具有写权限，也不能删除该文件，该权限只对目录有效.\n具体使用如下\nchmod u+s temp — 为 temp 文件加上 setuid 标志. (setuid 只对文件有效)\nchmod g+s tempdir — 为 tempdir 目录加上 setgid 标志 (setgid 只对目录有效)\nchmod o+t temp — 为 temp 文件加上 sticky 标志 (sticky 只对文件有效) *\n\n\n浏览器打开 localhost, 正常就能打开 nginx 默认的首页面\nnginx 推流配置sudo vim /opt/nginx/conf/nginx.conf\nrtmp {\n  server {\n      listen 1935;\n      application rtmplive_demo {\n          live on;\n          max_connections 1024;\n      }\n      application hlsvideo {\n          live on;\n          hls on;\n          hls_path /home/bz/Desktop/video/hlsvideo; # 推流存放文件夹,自定义\n          hls_fragment 1s;\n      }\n  }\n}\n\nlocation ^~ /hlsvideo {\n  types {\n    application/vnd.apple.mpegurl    m3u8;\n    video/mp2t ts;\n  }\n  root /home/bz/Desktop/video; # 此处不能写/home/bz/Desktop/video/hlsvideo,因为路径中带了一层hlsvideo了,如果写上hlsvideo会导致读取m3u8文件404\n  add_header Cache-Control    no-cache;\n}\n\nsudo /opt/nginx/sbin/nginx -t // 测试配置文件是否 ok\nsudo /opt/nginx/sbin/nginx -s reload\n测试 rtmp 推流ffmpeg -re -i ./龙珠超.布罗利.mp4 -vcodec libx264 -vprofile baseline -acodec aac -ar 44100 -strict -2 -ac 1 -f flv -s 1280x720 -q 10 rtmp://192.168.100.31:1935/rtmplive_demo/longzhuchao\n注:rtmp://192.168.100.31:1935/rtmplive_demo/longzhuchao rtmp流地址,其中rtmplive_demo必须和nginx.conf中\napplication中的rtmplive_demo名称必须一致,否则导致推流不成功\n\n打开 VLC Media Player 测试\n在工具栏” 媒体 -&gt; 打开网络串流” 然后输入 rtmp://192.168.100.31:1935/rtmplive_demo/longzhuchao 点击确定即可进行直播预览转换后的 rtmp 视频流。效果如图\n\n测试 HLS 推流ffmpeg -re -i ./龙珠超.布罗利.mp4 -vcodec libx264 -vprofile baseline -acodec aac -ar 44100 -strict -2 -ac 1 -f flv -s 1280x720 -q 10 rtmp://192.168.100.31:1935/hlsvideo/longzhuchao\n注:rtmp://192.168.100.31:1935/hlsvideo/longzhuchao,其中hlsvideo必须和nginx.conf中\napplication中hlsvideo名称必须一致,否则导致推流不成功\n\n打开 VLC Media Player 测试\nHLS 测试地址是 http 协议的。访问路径是 nginx 中 http 节点下 server 节点配置的。此处是 http://192.168.100.31/hlsvideo/longzhuchao.m3u8\n在工具栏” 媒体 -&gt; 打开网络串流” 然后输入 http://192.168.100.31/hlsvideo/longzhuchao.m3u8 点击确定即可进行直播预览转换后的 rtmp 视频流。效果如图\n\n","tags":["nginx","rtmp"]},{"title":"远程 tomcat 配置 jconsole 连接监测 jvm 参数","url":"/%E8%BF%9C%E7%A8%8Btomcat%E9%85%8D%E7%BD%AEjconsole%E8%BF%9E%E6%8E%A5%E7%9B%91%E6%B5%8Bjvm%E5%8F%82%E6%95%B0/","content":"1. 在 tomcat 的 bin 目录下 catalina.sh 文件首部增加以下配置 (注意：不用换行)\nCATALINA_OPTS=\"-Dfile.encoding=UTF-8 -server -Xms256m -Xmx256m -Djava.rmi.server.hostname=0.0.0.0 -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=10001 -Dcom.sun.management.jmxremote.rmi.port=10001 -Dcom.sun.management.jmxremote.authenticate=true -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.password.file=./conf/jmxremote.password -Dcom.sun.management.jmxremote.access.file=./conf/jmxremote.access\"\n\n其中-Xms256m -Xmx256m是配置jvm虚拟机参数的,最小堆内存和最大堆内存,推荐保持一致,如果不一致会增加gc回收次数,\n对性能有严重影响.\n-Djava.rmi.server.hostname:本机的ip地址,可设置为0.0.0.0\n-Dcom.sun.management.jmxremote.port:监控的端口.不能和其他运行的端口相冲突\n-Dcom.sun.management.jmxremote.authenticate:需要授权才能进行连接\n-Dcom.sun.management.jmxremote.password.file:指定配置授权的密码文件存放位置,推荐放入到tomcat的conf目录下\n-Dcom.sun.management.jmxremote.access.file:指定配置授权账户的权限的文件存放位置,推荐放入到tomcat的conf目录下\n\n2. 在 tomcat 的 bin 目录下 startup.sh 文件首部增加以下配置\nJAVA_OPTS=\"-Djava.rmi.server.hostname=0.0.0.0\"\n\n3. 启动本地的 jconsole 即可，输入远程 ip 和端口，username 和 password 即可连接\n注意:\n1.配置授权的2个文件是在系统的%JAVA_HOME%/jre/lib/management目录下可以找到对应的模板.将其复制到tomcat的conf目录下,\n并将jmxremote.password.template重命名为jmxremote.password\n2.jmxremote.access用户权限分readonly和readwrite两种，在jmxremote.access尾部添加用户权限\"admin  readwrite\",\n其中admin代表远程授权的用户名\n3.在jmxremote.password尾部添加用户密码\"admin 123456\"其中admin代表用户名,123456代表对应的密码\n4.对jmxremote.access和jmxremote.password文件进行授权,chmod 600  jmxremote.access和\nchmod 600 jmxremote.password\n5.针对为什么在startup.sh文件中增加对应的-Djava.rmi.server.hostname=0.0.0.0配置,主要是因为在不加配置的情况下,\n用shutdown.sh关闭tomcat的时候会报该端口已经被占用,因为关闭tomcat时候，还会读取catalina.sh.所以推荐在startup.sh文件中配置\n6.一般情况下远程服务器系统是开启防火墙的,所以还需要将10001端口配置为允许访问\n7.如果配置一切无误,还是连接不上的话,请将0.0.0.0换成对应的IP地址.因为亲测在Ubuntu下0.0.0.0能连接成功,\n但是在centos7下连接不成功\n\n","tags":["java","tomcat","jconsole","jvm"]}]